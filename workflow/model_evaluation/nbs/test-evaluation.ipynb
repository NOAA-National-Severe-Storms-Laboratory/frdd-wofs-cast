{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27657ec1",
   "metadata": {},
   "source": [
    "## Unit Testing for the Evaluator \n",
    "\n",
    "- Test that the .update() functionality works\n",
    "- Test that the .finalize() functionality works\n",
    "\n",
    "- Test \n",
    "    * MSE\n",
    "    * Object Matching \n",
    "    * PMM storm structure \n",
    "    * Spectra \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcab7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "package_path = os.path.dirname(os.path.dirname(os.getcwd())) \n",
    "sys.path.insert(0, package_path)\n",
    "\n",
    "from wofscast.evaluate.metrics import (MSE,\n",
    "                                       ObjectBasedContingencyStats,\n",
    "                                       PowerSpectra,\n",
    "                                       FractionsSkillScore,\n",
    "                                       PMMStormStructure,\n",
    "                                       )\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed4239",
   "metadata": {},
   "source": [
    "### MSE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c31a82a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MSE' object has no attribute 'results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest passed: RMSE with batch dimension is correct.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mtest_mse_with_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m, in \u001b[0;36mtest_mse_with_batches\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m mse_calculator \u001b[38;5;241m=\u001b[39m MSE()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Perform 2 update calls for batch=0 and batch=1\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mmse_calculator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m mse_calculator\u001b[38;5;241m.\u001b[39mupdate(forecast\u001b[38;5;241m.\u001b[39misel(batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), truth\u001b[38;5;241m.\u001b[39misel(batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Finalize and get the RMSE\u001b[39;00m\n",
      "File \u001b[0;32m~/python_packages/frdd-wofs-cast/wofscast/evaluate/metrics.py:74\u001b[0m, in \u001b[0;36mMSE.update\u001b[0;34m(self, forecast, truth)\u001b[0m\n\u001b[1;32m     70\u001b[0m diff \u001b[38;5;241m=\u001b[39m (forecast\u001b[38;5;241m-\u001b[39mtruth)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     72\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_preserving_time(diff)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults_\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_ \u001b[38;5;241m=\u001b[39m diff\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:    \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MSE' object has no attribute 'results_'"
     ]
    }
   ],
   "source": [
    "# Test the MSE class with batch size of 2\n",
    "def test_mse_with_batches():\n",
    "    # Create a fake dataset for forecast and truth with batch dimension\n",
    "    # Dimensions: ('batch', 'time', 'lat', 'lon')\n",
    "    batch_size = 2\n",
    "    time = np.arange(5)  # 5 time steps\n",
    "    lat = np.arange(2)  # 2 lat points\n",
    "    lon = np.arange(2)  # 2 lon points\n",
    "\n",
    "    forecast_data = np.ones()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Create known forecast and truth data with batch size of 2\n",
    "    forecast_data = np.array([[[[1, 2], [3, 4]], [[1, 2], [3, 4]], [[1, 2], [3, 4]], [[1, 2], [3, 4]], [[1, 2], [3, 4]]],\n",
    "                              [[[2, 3], [4, 5]], [[2, 3], [4, 5]], [[2, 3], [4, 5]], [[2, 3], [4, 5]], [[2, 3], [4, 5]]]])\n",
    "\n",
    "    truth_data = np.array([[[[1, 1], [3, 3]], [[1, 1], [3, 3]], [[1, 1], [3, 3]], [[1, 1], [3, 3]], [[1, 1], [3, 3]]],\n",
    "                           [[[2, 2], [4, 4]], [[2, 2], [4, 4]], [[2, 2], [4, 4]], [[2, 2], [4, 4]], [[2, 2], [4, 4]]]])\n",
    "\n",
    "    # Create xarray Datasets for forecast and truth with the 'batch' dimension\n",
    "    forecast = xr.Dataset({\n",
    "        'var1': (['batch', 'time', 'lat', 'lon'], forecast_data),\n",
    "    }, coords={'batch': np.arange(batch_size), 'time': time, 'lat': lat, 'lon': lon})\n",
    "\n",
    "    truth = xr.Dataset({\n",
    "        'var1': (['batch', 'time', 'lat', 'lon'], truth_data),\n",
    "    }, coords={'batch': np.arange(batch_size), 'time': time, 'lat': lat, 'lon': lon})\n",
    "\n",
    "    # Initialize the MSE class\n",
    "    mse_calculator = MSE()\n",
    "\n",
    "    # Perform 2 update calls for batch=0 and batch=1\n",
    "    mse_calculator.update(forecast.isel(batch=0), truth.isel(batch=0))\n",
    "    mse_calculator.update(forecast.isel(batch=1), truth.isel(batch=1))\n",
    "\n",
    "    # Finalize and get the RMSE\n",
    "    rmse_results = mse_calculator.finalize()\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Final RMSE Results:\")\n",
    "    print(rmse_results)\n",
    "\n",
    "    # Manually compute the expected RMSE across both batches\n",
    "    expected_rmse = np.sqrt(np.mean(np.concatenate([(forecast_data[0] - truth_data[0]) ** 2, \n",
    "                                                    (forecast_data[1] - truth_data[1]) ** 2]), axis=(0, 1, 2)))\n",
    "\n",
    "    # Assert that the computed RMSE matches the expected RMSE\n",
    "    np.testing.assert_almost_equal(rmse_results['var1_rmse'].values, expected_rmse, decimal=5)\n",
    "    print(\"Test passed: RMSE with batch dimension is correct.\")\n",
    "\n",
    "# Run the test\n",
    "test_mse_with_batches()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75135f",
   "metadata": {},
   "source": [
    "### Object Matching Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the ObjectBasedContingencyStats class with a larger area (10x10)\n",
    "def test_object_based_metrics_larger_area():\n",
    "    # Create a fake dataset for forecast and truth with storms\n",
    "    # Dimensions: ('batch', 'time', 'lat', 'lon')\n",
    "    batch_size = 2\n",
    "    time = np.arange(3)  # 3 time steps\n",
    "    lat = np.arange(10)  # 10 lat points\n",
    "    lon = np.arange(10)  # 10 lon points\n",
    "\n",
    "    # Designed for 1 hit and false per batch update, repeated \n",
    "    # for each time step. \n",
    "    n_expected_hits = len(time)*batch_size \n",
    "    n_expected_false_alarms = len(time)*batch_size\n",
    "    # For misses, there are 2 misses per batch updated, \n",
    "    # repeated for each time step. \n",
    "    n_expected_misses = len(time)*2*batch_size\n",
    "    \n",
    "    # Create labelled regions for storms in forecast and truth\n",
    "    # Batch 0: 1 hit, 1 false alarm, 1 miss\n",
    "    forecast_data_batch_0 = np.zeros((3, 10, 10))\n",
    "    truth_data_batch_0 = np.zeros((3, 10, 10))\n",
    "\n",
    "    # Label storms in batch 0\n",
    "    # Forecast storm 1 matches truth, forecast storm 2 is a false alarm, truth storm 3 is a miss\n",
    "    forecast_data_batch_0[:, 1:4, 1:4] = 1  # Storm 1 (hit)\n",
    "    forecast_data_batch_0[:, 6:8, 6:8] = 2  # Storm 2 (false alarm)\n",
    "    \n",
    "    truth_data_batch_0[:, 1:4, 1:4] = 1     # Storm 1 (hit)\n",
    "    truth_data_batch_0[:, 7:9, 1:3] = 3     # Storm 3 (miss)\n",
    "    truth_data_batch_0[:, 9:, 1:3] = 9     # Storm 4 (miss)\n",
    "    \n",
    "    \n",
    "    # Batch 1: Different configuration with hits, false alarms, and misses\n",
    "    forecast_data_batch_1 = np.zeros((3, 10, 10))\n",
    "    truth_data_batch_1 = np.zeros((3, 10, 10))\n",
    "\n",
    "    # Label storms in batch 1\n",
    "    forecast_data_batch_1[:, 2:5, 2:5] = 4  # Storm 4 (hit)\n",
    "    forecast_data_batch_1[:, 5:7, 7:9] = 5  # Storm 5 (false alarm)\n",
    "    truth_data_batch_1[:, 2:5, 2:5] = 4     # Storm 4 (hit)\n",
    "    truth_data_batch_1[:, 6:8, 1:4] = 6     # Storm 6 (miss)\n",
    "    truth_data_batch_1[:, 9:, 1:3] = 7     # Storm 4 (miss)\n",
    "\n",
    "    # Create xarray Datasets for forecast and truth with the 'batch' dimension\n",
    "    forecast = xr.Dataset({\n",
    "        'storms': (['batch', 'time', 'lat', 'lon'], np.stack([forecast_data_batch_0, forecast_data_batch_1]))\n",
    "    }, coords={'batch': np.arange(batch_size), 'time': time, 'lat': lat, 'lon': lon})\n",
    "\n",
    "    truth = xr.Dataset({\n",
    "        'storms': (['batch', 'time', 'lat', 'lon'], np.stack([truth_data_batch_0, truth_data_batch_1]))\n",
    "    }, coords={'batch': np.arange(batch_size), 'time': time, 'lat': lat, 'lon': lon})\n",
    "\n",
    "    # Initialize the ObjectBasedContingencyStats class\n",
    "    obj_stats = ObjectBasedContingencyStats(matching_dist=1)\n",
    "\n",
    "    # Perform 2 update calls for batch=0 and batch=1\n",
    "    obj_stats.update(forecast.isel(batch=0), truth.isel(batch=0))\n",
    "    obj_stats.update(forecast.isel(batch=1), truth.isel(batch=1))\n",
    "\n",
    "    # Finalize and get the results\n",
    "    results = obj_stats.finalize()\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Final Object-Based Metrics Results:\")\n",
    "    print(results)\n",
    "\n",
    "    # Perform basic assertions\n",
    "    assert results['wofscast_vs_wofs_hits'].sum() == n_expected_hits, f\"Number of hits should be {n_expected_hits}\"\n",
    "    assert results['wofscast_vs_wofs_false_alarms'].sum() == n_expected_false_alarms, f\"Number of false alarms should be {n_expected_false_alarms}\"\n",
    "    assert results['wofscast_vs_wofs_misses'].sum() == n_expected_misses, f\"Number of misses should be {n_expected_misses}\"\n",
    "    \n",
    "    # POD\n",
    "    expected_pod = n_expected_hits / (n_expected_hits + n_expected_misses)\n",
    "    pod = results['wofscast_vs_wofs_pod'].isel(time=0).values\n",
    "    np.testing.assert_almost_equal(pod, expected_pod, decimal=5)\n",
    "    \n",
    "    # SR\n",
    "    expected_sr = n_expected_hits / (n_expected_hits + n_expected_false_alarms)\n",
    "    sr = results['wofscast_vs_wofs_sr'].isel(time=0).values\n",
    "    np.testing.assert_almost_equal(sr, expected_sr, decimal=5)\n",
    "    \n",
    "    # CSI\n",
    "    expected_csi = n_expected_hits / (n_expected_hits + n_expected_false_alarms + n_expected_misses)\n",
    "    csi = results['wofscast_vs_wofs_csi'].isel(time=0).values\n",
    "    np.testing.assert_almost_equal(csi, expected_csi, decimal=5)\n",
    "    \n",
    "    # FB\n",
    "    expected_fb = expected_pod / expected_sr\n",
    "    fb = results['wofscast_vs_wofs_fb'].isel(time=0).values\n",
    "    np.testing.assert_almost_equal(fb, expected_fb, decimal=5)\n",
    "    \n",
    "    print(\"Test passed: Object-based metrics are correct for larger area.\")\n",
    "\n",
    "    return forecast, truth\n",
    "    \n",
    "# Run the test\n",
    "forecast, truth = test_object_based_metrics_larger_area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a64b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth['storms'].isel(batch=0, time=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast['storms'].isel(batch=1, time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb531b8d",
   "metadata": {},
   "source": [
    "### Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ebd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_power_spectra_with_constant_data():\n",
    "    # Dimensions\n",
    "    batch_size = 1\n",
    "    time_steps = 3\n",
    "    levels = 1\n",
    "    lat_points = 10\n",
    "    lon_points = 10\n",
    "\n",
    "    # Create constant forecast and truth data\n",
    "    constant_forecast = np.ones((batch_size, time_steps, levels, lat_points, lon_points))\n",
    "    constant_truth = np.ones((batch_size, time_steps, levels, lat_points, lon_points))\n",
    "\n",
    "    # Create xarray Datasets for forecast and truth\n",
    "    forecast = xr.Dataset({\n",
    "        'var1': (['batch', 'time', 'level', 'lat', 'lon'], constant_forecast)\n",
    "    }, coords={'batch': np.arange(batch_size), 'time': np.arange(time_steps), \n",
    "               'level': np.arange(levels), 'lat': np.arange(lat_points), 'lon': np.arange(lon_points)})\n",
    "\n",
    "    truth = xr.Dataset({\n",
    "        'var1': (['batch', 'time', 'level', 'lat', 'lon'], constant_truth)\n",
    "    }, coords={'batch': np.arange(batch_size), 'time': np.arange(time_steps), \n",
    "               'level': np.arange(levels), 'lat': np.arange(lat_points), 'lon': np.arange(lon_points)})\n",
    "\n",
    "    # Initialize the PowerSpectra class\n",
    "    spectra_calculator = PowerSpectra(grid_spacing_in_km=3.0, variables=['var1'], level=0)\n",
    "\n",
    "    # Call update for the first batch\n",
    "    spectra_calculator.update(forecast.isel(batch=0), truth.isel(batch=0))\n",
    "\n",
    "    # Finalize and get the results\n",
    "    results = spectra_calculator.finalize()\n",
    "\n",
    "    # Since the input is constant, we expect flat spectra\n",
    "    forecast_spectra = results['var1_forecast_spectra'].values\n",
    "    truth_spectra = results['var1_truth_spectra'].values\n",
    "\n",
    "    # Assert the spectra are flat (constant or zero)\n",
    "    assert np.allclose(forecast_spectra, forecast_spectra[0]), \"Forecast spectra should be flat\"\n",
    "    assert np.allclose(truth_spectra, truth_spectra[0]), \"Truth spectra should be flat\"\n",
    "    print(\"Test passed: Constant data spectra are correct.\")\n",
    "\n",
    "# Run the test\n",
    "test_power_spectra_with_constant_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0468004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
