{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ed5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os \n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from wofscast.model import WoFSCastModel\n",
    "from wofscast.border_mask import BORDER_MASK_NUMPY\n",
    "\n",
    "from wofscast.data_generator import (load_chunk, \n",
    "                                     WRFZarrFileProcessor,\n",
    "                                     WoFSDataProcessor, \n",
    "                                     dataset_to_input,\n",
    "                                     ZarrDataGenerator\n",
    "                                    )\n",
    "from wofscast import checkpoint\n",
    "from wofscast.wofscast_task_config import (DBZ_TASK_CONFIG, \n",
    "                                           WOFS_TASK_CONFIG, \n",
    "                                           DBZ_TASK_CONFIG_1HR,\n",
    "                                           DBZ_TASK_CONFIG_FULL\n",
    "                                          )\n",
    "\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def get_files_for_year(year):\n",
    "    \"\"\"Get all zarr files within a directory.\"\"\"\n",
    "    year_path = join(base_path, year)\n",
    "    with os.scandir(year_path) as it:\n",
    "        return [join(year_path, entry.name) for entry in it if entry.is_dir() and entry.name.endswith('.zarr')] \n",
    "\n",
    "def get_random_subset(input_list, subset_size, seed=123):\n",
    "    \"\"\"\n",
    "    Get a random subset of a specified size from the input list.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_list : list\n",
    "        The original list from which to draw the subset.\n",
    "    subset_size : int\n",
    "        The size of the subset to be drawn.\n",
    "    seed : int, optional\n",
    "        The seed for the random number generator. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        A random subset of the input list.\n",
    "    \"\"\"\n",
    "    if subset_size > len(input_list):\n",
    "        raise ValueError(\"subset_size must be less than or equal to the length of the input list\")\n",
    "    \n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    return random.sample(input_list, subset_size)\n",
    "\n",
    "def pad_to_multiple_of_16(tensor):\n",
    "    _, _, h, w = tensor.size()\n",
    "    pad_h = (16 - h % 16) % 16\n",
    "    pad_w = (16 - w % 16) % 16\n",
    "    pad_top = pad_h // 2\n",
    "    pad_bottom = pad_h - pad_top\n",
    "    pad_left = pad_w // 2\n",
    "    pad_right = pad_w - pad_left\n",
    "    padded_tensor = F.pad(tensor, (pad_left, pad_right, pad_top, pad_bottom))\n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9836b60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/mflora/miniconda3/envs/wofs-cast-gen/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/work/mflora/miniconda3/envs/wofs-cast-gen/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "WARNING:absl:Skipping gradient checkpointing for sequence length of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to /work/mflora/wofs-cast-data/predictions/wofscast_dataset.pt\n"
     ]
    }
   ],
   "source": [
    "OUT_BASE_PATH = '/work/mflora/wofs-cast-data/predictions'\n",
    "    \n",
    "base_path = '/work/mflora/wofs-cast-data/datasets_zarr/'\n",
    "MODEL_PATH = '/work/mflora/wofs-cast-data/model/wofscast_baseline.npz'\n",
    "norm_stats_path = '/work/mflora/wofs-cast-data/full_normalization_stats'\n",
    "    \n",
    "model = WoFSCastModel(norm_stats_path = norm_stats_path)\n",
    "model.load_model(MODEL_PATH)\n",
    "    \n",
    "years = ['2019', '2020']\n",
    "with ThreadPoolExecutor() as executor:\n",
    "        paths = []\n",
    "        for files in executor.map(get_files_for_year, years):\n",
    "            paths.extend(files)\n",
    "    \n",
    "n_batches = 32\n",
    "gpu_batch_size = 32 \n",
    "paths = get_random_subset(paths, n_batches, seed=42)\n",
    "\n",
    "generator = ZarrDataGenerator(WOFS_TASK_CONFIG, \n",
    "                              cpu_batch_size=2*gpu_batch_size, \n",
    "                              gpu_batch_size=gpu_batch_size, n_workers=24)\n",
    "\n",
    "gen = generator(paths)\n",
    "\n",
    "predicted_refl_list = []\n",
    "truth_refl_list = []\n",
    "\n",
    "for j, (inputs, targets, forcings) in enumerate(gen):                    \n",
    "    predictions = model.predict(inputs, targets, forcings)\n",
    "  \n",
    "    predicted_refl = predictions['COMPOSITE_REFL_10CM'].values.squeeze() # shape (gpu_batch_size, ny, nx)\n",
    "    truth_refl = targets['COMPOSITE_REFL_10CM'].values.squeeze() # shape (gpu_batch_size, ny, nx)\n",
    "    \n",
    "    # Add channel dimension\n",
    "    predicted_refl = predicted_refl[:, np.newaxis, :, :]\n",
    "    truth_refl = truth_refl[:, np.newaxis, :, :]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    predicted_refl_tensor = torch.tensor(predicted_refl, dtype=torch.float32)\n",
    "    truth_refl_tensor = torch.tensor(truth_refl, dtype=torch.float32)\n",
    "    \n",
    "     # Apply padding\n",
    "    predicted_refl_tensor = pad_to_multiple_of_16(predicted_refl_tensor)\n",
    "    truth_refl_tensor = pad_to_multiple_of_16(truth_refl_tensor)\n",
    "\n",
    "    predicted_refl_list.append(predicted_refl_tensor)\n",
    "    truth_refl_list.append(truth_refl_tensor)\n",
    "\n",
    "# Concatenate all numpy arrays and convert to torch tensors\n",
    "predicted_refl_all = torch.cat(predicted_refl_list, dim=0)\n",
    "truth_refl_all = torch.cat(truth_refl_list, dim=0)\n",
    "\n",
    "# Create the ConditionalGOES16_Nowcast compatible dataset\n",
    "conditional_images = predicted_refl_all  # Use predicted reflectivity as conditional images\n",
    "next_image = truth_refl_all  # Use true reflectivity as next images\n",
    "\n",
    "# Save the dataset\n",
    "dataset_path = '/work/mflora/wofs-cast-data/predictions/wofscast_dataset.pt'\n",
    "torch.save({\n",
    "    'next_image': next_image,\n",
    "    'conditional_images': conditional_images,\n",
    "    'metadata': None  # Add metadata if available\n",
    "}, dataset_path)\n",
    "\n",
    "print(f\"Dataset saved to {dataset_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
