{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6043bad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [cuda(id=0), cuda(id=1)]\n"
     ]
    }
   ],
   "source": [
    "import sys, os \n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "# @title Imports\n",
    "import dataclasses\n",
    "import datetime\n",
    "import functools\n",
    "import math\n",
    "import re\n",
    "from typing import Optional\n",
    "from glob import glob\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "#from google.cloud import storage\n",
    "from wofscast import autoregressive\n",
    "from wofscast import casting\n",
    "from wofscast import checkpoint\n",
    "from wofscast import data_utils\n",
    "from wofscast import my_graphcast as graphcast\n",
    "from wofscast import normalization\n",
    "from wofscast import rollout\n",
    "from wofscast import xarray_jax\n",
    "from wofscast import xarray_tree\n",
    "from IPython.display import HTML\n",
    "import ipywidgets as widgets\n",
    "import haiku as hk\n",
    "import jax\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import xarray #as xr\n",
    "\n",
    "# For training the weights!\n",
    "import optax\n",
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax import device_put\n",
    "\n",
    "from jax import pmap, device_put, local_device_count\n",
    "\n",
    "# Check available devices\n",
    "print(\"Available devices:\", jax.devices())\n",
    "\n",
    "from jax import tree_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255ab717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' usage: stdbuf -oL python -u train_graphcast_with_wofs.py > & log_trainer_models & '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notes on GraphCast Changes to run with WoFS data.\n",
    "\n",
    "# 1. Introduced time dimension with timedeltas dataset\n",
    "# 2. Introduce level dimension to the dataset \n",
    "# 3. Added try/excepts for xarray_jax to avoid PyTree errors about registry \n",
    "# 4. Cuda-enabled jaxlib error; had to install jax with this command for Cuda 11.8 \n",
    "# pip install --upgrade \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "# 5. Need to add the forcing variables (radiation) to the dataset\n",
    "# 6. Xarray 2024.1.1 raised TracerArrayConversionError, downgraded to 2023.7.0, the version \n",
    "#    used in colab in the demo notebook.\n",
    "\n",
    "\n",
    "\"\"\" usage: stdbuf -oL python -u train_graphcast_with_wofs.py > & log_trainer_models & \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ca1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_parameters(params_dict):\n",
    "    \"\"\"\n",
    "    Count the total number of parameters in a nested dictionary of parameters.\n",
    "    Assumes that the dictionary contains `Array` objects that have a `size` attribute.\n",
    "    \n",
    "    Args:\n",
    "    - params_dict (dict): A nested dictionary of parameters.\n",
    "    \n",
    "    Returns:\n",
    "    - int: The total number of parameters.\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "\n",
    "    # Define a helper function to recurse through the dictionary\n",
    "    def recurse_through_dict(d):\n",
    "        nonlocal total_params\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, dict):\n",
    "                recurse_through_dict(v)  # Recurse if value is a dictionary\n",
    "            else:\n",
    "                # Assume that the object has a 'size' attribute\n",
    "                total_params += v.size\n",
    "    \n",
    "    recurse_through_dict(params_dict)\n",
    "    return total_params\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='//'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def save_model_params(d, file_path):\n",
    "    flat_dict = flatten_dict(d)\n",
    "    # Convert JAX arrays to NumPy for saving\n",
    "    np_dict = {k: np.array(v) if isinstance(v, jnp.ndarray) else v for k, v in flat_dict.items()}\n",
    "    np.savez(file_path, **np_dict)\n",
    "\n",
    "\n",
    "base_path = '/work/mflora/wofs-cast-data/model'\n",
    "params_path = os.path.join(base_path, 'params.npz')\n",
    "\n",
    "###save_model_params(params, params_path)\n",
    "\n",
    "\n",
    "def unflatten_dict(d, sep='//'):\n",
    "    result_dict = {}\n",
    "    for flat_key, value in d.items():\n",
    "        keys = flat_key.split(sep)\n",
    "        d = result_dict\n",
    "        for key in keys[:-1]:\n",
    "            if key not in d:\n",
    "                d[key] = {}\n",
    "            d = d[key]\n",
    "        d[keys[-1]] = value\n",
    "    return result_dict\n",
    "\n",
    "def load_model_params(file_path):\n",
    "    with np.load(file_path, allow_pickle=True) as npz_file:\n",
    "        # Convert NumPy arrays back to JAX arrays\n",
    "        jax_dict = {k: jnp.array(v) for k, v in npz_file.items()}\n",
    "    return unflatten_dict(jax_dict)\n",
    "\n",
    "###params = load_model_params(params_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e495165",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_size = 6\n",
    "latent_size = 64\n",
    "gnn_msg_steps = 8\n",
    "hidden_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29ede3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables = ['U', 'V', 'W', 'T']#, 'P', 'REFL_10CM', 'UP_HELI_MAX']\n",
    "target_variables = ['U', 'V', 'W', 'T']#, 'P', 'REFL_10CM', 'UP_HELI_MAX']\n",
    "forcing_variables = [\"XLAND\"]\n",
    "\n",
    "vars_2D = [] #['UP_HELI_MAX']\n",
    "\n",
    "# Weights used in the loss equation.\n",
    "VARIABLE_WEIGHTS = {v : 1.0 for v in target_variables}\n",
    "#VARIABLE_WEIGHTS['REFL_10CM'] = 2.0\n",
    "#VARIABLE_WEIGHTS['UP_HELI_MAX'] = 2.0\n",
    "\n",
    "# Not pressure levels, but just vertical array indices at the moment. \n",
    "pressure_levels = np.arange(0, 40) #list(np.arange(0,40,2))\n",
    "radius_query_fraction_edge_length=5\n",
    "\n",
    "# Loads data from the past 10 minutes and \n",
    "# creates a target lead time 5-30, in 5 min intervals\n",
    "input_duration = '20min'\n",
    "train_lead_times = '10min' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753d04b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = graphcast.ModelConfig(\n",
    "      resolution=0,\n",
    "      mesh_size=mesh_size,\n",
    "      latent_size=latent_size,\n",
    "      gnn_msg_steps=gnn_msg_steps,\n",
    "      hidden_layers=hidden_layers,\n",
    "      radius_query_fraction_edge_length=radius_query_fraction_edge_length)\n",
    "\n",
    "task_config = graphcast.TaskConfig(\n",
    "      input_variables=input_variables,\n",
    "      target_variables=target_variables,\n",
    "      forcing_variables=forcing_variables,\n",
    "      pressure_levels=pressure_levels,\n",
    "      input_duration=input_duration,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b19de0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Train Inputs:   {'batch': 204, 'time': 2, 'level': 40, 'lat': 150, 'lon': 150}\n",
      "Train Targets:  {'batch': 204, 'time': 1, 'level': 40, 'lat': 150, 'lon': 150}\n",
      "Train Forcings: {'batch': 204, 'time': 1, 'lat': 150, 'lon': 150}\n",
      "********************************************************************************\n",
      "Eval Inputs:    {'batch': 1, 'time': 2, 'lat': 150, 'lon': 150, 'level': 40}\n",
      "Eval Targets:   {'batch': 1, 'time': 1, 'lat': 150, 'lon': 150, 'level': 40}\n",
      "Eval Forcings:  {'batch': 1, 'time': 1, 'lat': 150, 'lon': 150}\n"
     ]
    }
   ],
   "source": [
    "# Load the data \n",
    "base_path = '/work/mflora/wofs-cast-data/train_datasets'\n",
    "\n",
    "train_inputs = xarray.load_dataset(os.path.join(base_path, 'train_inputs.nc'))\n",
    "train_targets = xarray.load_dataset(os.path.join(base_path, 'train_targets.nc'))\n",
    "train_forcings = xarray.load_dataset(os.path.join(base_path, 'train_forcings.nc'))\n",
    "\n",
    "train_targets = train_targets.isel(time = [0])\n",
    "train_forcings= train_forcings.isel(time = [0])\n",
    "\n",
    "train_inputs = train_inputs.transpose(\"batch\", 'time', 'lat', 'lon', 'level')\n",
    "train_targets = train_targets.transpose(\"batch\", 'time', 'lat', 'lon', 'level')\n",
    "train_forcings = train_forcings.transpose(\"batch\", 'time', 'lat', 'lon')\n",
    "\n",
    "eval_inputs = train_inputs.isel(batch=[0])\n",
    "eval_targets = train_targets.isel(batch=[0])\n",
    "eval_forcings = train_forcings.isel(batch=[0])\n",
    "\n",
    "print(\"*\"*80)\n",
    "print(\"Train Inputs:  \", train_inputs.dims.mapping)\n",
    "print(\"Train Targets: \", train_targets.dims.mapping)\n",
    "print(\"Train Forcings:\", train_forcings.dims.mapping)\n",
    "print(\"*\"*80)\n",
    "print(\"Eval Inputs:   \", eval_inputs.dims.mapping)\n",
    "print(\"Eval Targets:  \", eval_targets.dims.mapping)\n",
    "print(\"Eval Forcings: \", eval_forcings.dims.mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4117c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the normalization datasets\n",
    "base_path = '/work/mflora/wofs-cast-data/normalization_stats'\n",
    "mean_by_level = xarray.load_dataset(os.path.join(base_path, 'mean_by_level.nc'))\n",
    "stddev_by_level = xarray.load_dataset(os.path.join(base_path, 'stddev_by_level.nc'))\n",
    "diffs_stddev_by_level = xarray.load_dataset(os.path.join(base_path, 'diffs_stddev_by_level.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3536613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping gradient checkpointing for sequence length of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_mesh_node=array([8321]), node_features.shape=(8321, 3)\n"
     ]
    }
   ],
   "source": [
    "# @title Build jitted functions, and possibly initialize random weights\n",
    "\n",
    "# Load saved model params and test! \n",
    "#model_params = None #load_model_params(params_path)\n",
    "#state = {}\n",
    "\n",
    "def construct_wrapped_graphcast(\n",
    "    model_config: graphcast.ModelConfig,\n",
    "    task_config: graphcast.TaskConfig):\n",
    "    \"\"\"Constructs and wraps the GraphCast Predictor.\"\"\"\n",
    "\n",
    "    # Deeper one-step predictor.\n",
    "    predictor = graphcast.GraphCast(model_config, task_config, VARIABLE_WEIGHTS, vars_2D)\n",
    "\n",
    "    # Modify inputs/outputs to `graphcast.GraphCast` to handle conversion to\n",
    "    # from/to float32 to/from BFloat16.\n",
    "    predictor = casting.Bfloat16Cast(predictor)\n",
    "\n",
    "    # Modify inputs/outputs to `casting.Bfloat16Cast` so the casting to/from\n",
    "    # BFloat16 happens after applying normalization to the inputs/targets.\n",
    "    predictor = normalization.InputsAndResiduals(\n",
    "      predictor,\n",
    "      diffs_stddev_by_level=diffs_stddev_by_level,\n",
    "      mean_by_level=mean_by_level,\n",
    "      stddev_by_level=stddev_by_level)\n",
    "\n",
    "    # Wraps everything so the one-step model can produce trajectories.\n",
    "    predictor = autoregressive.Predictor(predictor, gradient_checkpointing=True)\n",
    "    \n",
    "    return predictor\n",
    "\n",
    "\n",
    "@hk.transform_with_state\n",
    "def run_forward(model_config, task_config, inputs, targets_template, forcings):\n",
    "  predictor = construct_wrapped_graphcast(model_config, task_config)\n",
    "  return predictor(inputs, targets_template=targets_template, forcings=forcings)\n",
    "\n",
    "\n",
    "@hk.transform_with_state\n",
    "def loss_fn(model_config, task_config, inputs, targets, forcings):\n",
    "    predictor = construct_wrapped_graphcast(model_config, task_config)\n",
    "    loss, diagnostics = predictor.loss(inputs, targets, forcings)\n",
    "    return xarray_tree.map_structure(\n",
    "      lambda x: xarray_jax.unwrap_data(x.mean(), require_jax=True),\n",
    "      (loss, diagnostics))\n",
    "\n",
    "def grads_fn(params, state, model_config, task_config, inputs, targets, forcings):\n",
    "    def _aux(params, state, i, t, f):\n",
    "        (loss, diagnostics), next_state = loss_fn.apply(\n",
    "            params, state, jax.random.PRNGKey(0), model_config, task_config,\n",
    "            i, t, f)\n",
    "        return loss, (diagnostics, next_state)\n",
    "      \n",
    "        (loss, (diagnostics, next_state)), grads = jax.value_and_grad(\n",
    "          _aux, has_aux=True)(params, state, inputs, targets, forcings)\n",
    "    return loss, diagnostics, next_state, grads\n",
    "\n",
    "# Jax doesn't seem to like passing configs as args through the jit. Passing it\n",
    "# in via partial (instead of capture by closure) forces jax to invalidate the\n",
    "# jit cache if you change configs.\n",
    "def with_configs(fn):\n",
    "  return functools.partial(\n",
    "      fn, model_config=model_config, task_config=task_config)\n",
    "\n",
    "# Always pass params and state, so the usage below are simpler\n",
    "def with_params(fn):\n",
    "  return functools.partial(fn, params=model_params, state=state)\n",
    "\n",
    "# Our models aren't stateful, so the state is always empty, so just return the\n",
    "# predictions. This is requiredy by our rollout code, and generally simpler.\n",
    "def drop_state(fn):\n",
    "  return lambda **kw: fn(**kw)[0]\n",
    "\n",
    "init_jitted = jax.jit(with_configs(run_forward.init))\n",
    "\n",
    "model_params, state = init_jitted(\n",
    "    rng=jax.random.PRNGKey(0),\n",
    "    inputs=train_inputs,\n",
    "    targets_template=train_targets,\n",
    "    forcings=train_forcings)\n",
    "\n",
    "#loss_fn_jitted = drop_state(with_params(jax.jit(with_configs(loss_fn.apply))))\n",
    "#grads_fn_jitted = with_params(jax.jit(with_configs(grads_fn)))\n",
    "#run_forward_jitted = drop_state(with_params(jax.jit(with_configs(\n",
    "#    run_forward.apply))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e840a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Parameters: 503264\n"
     ]
    }
   ],
   "source": [
    "num = count_total_parameters(model_params)\n",
    "print(f'Num of Parameters: {num}')\n",
    "\n",
    "base_path = '/work/mflora/wofs-cast-data/model'\n",
    "params_path = os.path.join(base_path, 'test_params.npz')\n",
    "save_model_params(model_params, params_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c188d35",
   "metadata": {},
   "source": [
    "### Training Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907a2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shard_xarray_dataset(dataset, num_devices=None):\n",
    "    \"\"\"\n",
    "    Shards an xarray.Dataset across multiple GPUs.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: xarray.Dataset to be sharded.\n",
    "    - num_devices: Number of GPUs to shard the dataset across. If None, uses all available GPUs.\n",
    "\n",
    "    Returns:\n",
    "    A list of sharded xarray.Dataset, one for each GPU.\n",
    "    \"\"\"\n",
    "    if num_devices is None:\n",
    "        num_devices = jax.local_device_count()\n",
    "\n",
    "    # Assuming the first dimension of each data variable is the batch dimension\n",
    "    batch_size = next(iter(dataset.data_vars.values())).shape[0]\n",
    "    shard_size = batch_size // num_devices\n",
    "\n",
    "    if batch_size % num_devices != 0:\n",
    "        raise ValueError(f\"Batch size {batch_size} is not evenly divisible by the number of devices {num_devices}.\")\n",
    "\n",
    "    sharded_datasets = []\n",
    "    for i in range(num_devices):\n",
    "        start_idx = i * shard_size\n",
    "        end_idx = start_idx + shard_size\n",
    "        # Use dataset.isel to select a subset of the batch dimension for each shard\n",
    "        shard = dataset.isel(indexers={'batch': slice(start_idx, end_idx)})\n",
    "        sharded_datasets.append(shard)\n",
    "\n",
    "    return xarray.concat(sharded_datasets, dim='devices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9e9d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replicate_for_devices(params, num_devices=None):\n",
    "    \"\"\"Replicate parameters for each device using jax.device_put_replicated.\"\"\"\n",
    "    if num_devices is None:\n",
    "        num_devices = jax.local_device_count()\n",
    "    devices = jax.devices()[:num_devices]\n",
    "    replicated = jax.device_put_replicated(params, devices)\n",
    "    return replicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75c47c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices: [cuda(id=0), cuda(id=1)]\n"
     ]
    }
   ],
   "source": [
    "# Check available devices\n",
    "print(\"Available devices:\", jax.devices())\n",
    "num_devices = jax.local_device_count()\n",
    "\n",
    "def _loss_fn(params, state, inputs, targets, forcings):\n",
    "        (loss, diagnostics), next_state = loss_fn.apply(params, state, \n",
    "                                                        jax.random.PRNGKey(0), \n",
    "                                                        model_config, \n",
    "                                                        task_config, \n",
    "                                                        inputs, targets, forcings)\n",
    "        return loss, (diagnostics, next_state)\n",
    "\n",
    "# Define the gradient function\n",
    "def train_step(params: dict, \n",
    "               state:dict, \n",
    "               inputs: xarray.Dataset, \n",
    "               targets : xarray.Dataset, \n",
    "               forcings : xarray.Dataset, \n",
    "               model_config, task_config):\n",
    "    \n",
    "    # Compute gradients and auxiliary outputs\n",
    "    gradient_fn = jax.value_and_grad(_loss_fn, has_aux=True)\n",
    "    (loss, (diagnostics, next_state)), grads = gradient_fn(params, state, inputs, targets, forcings)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Compute the global norm of all gradients\n",
    "    total_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in tree_util.tree_leaves(grads)))\n",
    "\n",
    "    # Clip gradients if the total norm exceeds the threshold\n",
    "    def clip_grads(g, clip_norm=32):\n",
    "        return jnp.where(total_norm > clip_norm, g * clip_norm / total_norm, g)\n",
    "\n",
    "    clipped_grads = tree_util.tree_map(clip_grads, grads)\n",
    "    \"\"\"\n",
    "    \n",
    "    return grads, loss, diagnostics \n",
    "    \n",
    "def update_step(optimiser, params, grads, opt_state):\n",
    "    \"\"\"Performs a single update step by applying gradients to parameters.\"\"\"\n",
    "    updates, opt_state = optimiser.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state\n",
    "\n",
    "def get_random_batches(inputs, targets, forcings, batch_size):\n",
    "    total_samples = inputs.dims['batch']\n",
    "    indices = np.arange(total_samples)\n",
    "    np.random.shuffle(indices)  # Randomly shuffle the indices\n",
    "\n",
    "    for start_idx in range(0, total_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        yield (inputs.isel(batch=batch_indices), \n",
    "               targets.isel(batch=batch_indices), \n",
    "               forcings.isel(batch=batch_indices))\n",
    "\n",
    "train_step_pmap = xarray_jax.pmap(with_configs(train_step), dim='devices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d5a7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters. \n",
    "TOTAL_LINEAR_EPOCHS = 50\n",
    "TOTAL_COSINE_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "checkpoint = False\n",
    "\n",
    "# Setup the learning rate schedule\n",
    "start_learning_rate = 1e-6  # Start from 0\n",
    "end_learning_rate = 1e-3  # Increase to 1e-3\n",
    "schedule = optax.linear_schedule(init_value=start_learning_rate, \n",
    "                                 end_value=end_learning_rate, \n",
    "                                 transition_steps=TOTAL_LINEAR_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62f65eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_mesh_node=array([8321]), node_features.shape=(8321, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:17:07.299288: E external/xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %compare.6959 = pred[638518,1]{1,0} compare(s32[638518,1]{1,0} %constant.271, s32[638518,1]{1,0} %broadcast.231), direction=GE, metadata={op_name=\"pmap(fn_passed_to_pmap)/jit(main)/transpose(jvp(grid2mesh_gnn))/_process/grid2mesh_gnn/_process_step/grid2mesh_gnn/ge\" source_file=\"/home/monte.flora/python_packages/frdd-wofs-cast/wofscast/deep_typed_graph_net.py\" source_line=219}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-02-29 11:17:07.696770: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.397560066s\n",
      "Constant folding an instruction is taking > 1s:\n",
      "\n",
      "  %compare.6959 = pred[638518,1]{1,0} compare(s32[638518,1]{1,0} %constant.271, s32[638518,1]{1,0} %broadcast.231), direction=GE, metadata={op_name=\"pmap(fn_passed_to_pmap)/jit(main)/transpose(jvp(grid2mesh_gnn))/_process/grid2mesh_gnn/_process_step/grid2mesh_gnn/ge\" source_file=\"/home/monte.flora/python_packages/frdd-wofs-cast/wofscast/deep_typed_graph_net.py\" source_line=219}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-02-29 11:17:17.196395: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.196437: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:17.196442: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.196446: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:17.196450: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.196453: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:17.196456: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:17.196459: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.196462: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:17.196465: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.196468: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:17.726435: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.726475: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:17.726478: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.726482: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:17.726484: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.726487: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:17.726490: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:17.726493: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.726496: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:17.726499: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:17.726502: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:18.165346: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:18.165381: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:18.165385: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:18.165388: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:18.165391: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:18.165394: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:18.165397: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:18.165400: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:18.165402: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:18.165405: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:18.165408: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:19.589198: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:19.589237: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:19.589241: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:19.589244: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:19.589247: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:19.589250: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:19.589253: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:19.589256: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:19.589258: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:19.589261: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:19.589264: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:20.210783: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.210812: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:20.210816: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.210820: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:20.210822: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.210825: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:20.210828: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:20.210831: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.210834: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:20.210837: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.210840: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:17:20.820015: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.820052: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:20.820056: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.820060: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:20.820063: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.820066: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:20.820069: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:20.820072: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.820075: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:20.820078: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:20.820081: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:21.393093: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:21.393130: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:21.393134: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:21.393137: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:21.393140: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:21.393143: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:21.393146: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:21.393149: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:21.393151: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:21.393154: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:21.393157: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:22.491357: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.491397: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:22.491400: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.491404: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:22.491406: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.491410: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:22.491413: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:22.491416: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.491418: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:22.491421: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.491424: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:22.872140: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.872182: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:22.872187: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.872190: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:22.872193: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.872196: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:22.872198: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:22.872201: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.872204: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:22.872207: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:22.872210: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:23.500947: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:23.500982: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:23.500986: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:23.500990: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:23.500992: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:23.500995: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:23.500998: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:23.501001: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:23.501004: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:23.501007: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:23.501009: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:24.615729: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:24.615775: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:24.615779: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:24.615782: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:24.615785: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:24.615788: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:24.615791: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:24.615794: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:24.615797: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:24.615799: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:24.615802: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:17:25.024853: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.024889: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:25.024893: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.024896: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.024899: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.024901: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.024904: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.024907: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.024910: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.024912: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.024916: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:25.389253: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.389286: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:25.389289: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.389292: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.389295: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.389298: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.389301: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.389303: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.389306: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.389309: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.389312: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:25.828200: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.828243: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:25.828247: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.828251: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.828254: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.828256: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.828259: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.828262: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.828265: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:25.828267: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:25.828270: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:26.888428: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:26.888461: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:26.888465: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:26.888468: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:26.888471: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:26.888474: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:26.888477: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:26.888480: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:26.888482: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:26.888485: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:26.888488: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:27.609685: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:27.609729: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:27.609732: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:27.609736: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:27.609739: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:27.609742: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:27.609745: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:27.609748: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:27.609751: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:27.609753: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:27.609756: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:28.187638: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:28.187673: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:28.187676: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:28.187679: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:28.187682: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:28.187685: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:28.187688: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:28.187691: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:28.187694: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:28.187697: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:28.187700: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:17:29.044622: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 8.38861e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.044658: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 8.45414e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:29.044662: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 8.38861e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.044665: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 8.45414e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:29.044668: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 8.38861e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.044671: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 8.45414e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:29.044673: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 8.45414e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:29.044676: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 8.38861e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.044679: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 8.45414e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:29.044682: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 8.38861e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.044685: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:29.650202: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.650249: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:29.650253: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.650256: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:29.650259: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.650262: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:29.650264: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:29.650267: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.650270: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:29.650273: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:29.650275: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:30.964700: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:30.964743: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:30.964747: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:30.964750: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:30.964753: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:30.964755: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:30.964758: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:30.964761: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:30.964764: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:30.964766: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:30.964769: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:32.086845: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:32.086887: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:32.086890: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:32.086893: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:32.086896: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:32.086899: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:32.086902: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:32.086905: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:32.086907: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:32.086910: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:32.086913: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:33.167940: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:33.167997: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 7.04512e+06, expected 1.02236e+07\n",
      "2024-02-29 11:17:33.168006: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:33.168009: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:33.168011: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:33.168014: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 6.94682e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:33.168017: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 7.01235e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:33.168020: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 6.91405e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:33.168023: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 6.97958e+06, expected 1.01581e+07\n",
      "2024-02-29 11:17:33.168026: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 6.94682e+06, expected 1.00925e+07\n",
      "2024-02-29 11:17:33.168028: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "INTERNAL: All algorithms tried for %convert.411 = f32[192,64]{1,0} convert(bf16[192,64]{1,0} %dot.409), metadata={op_name=\"pmap(fn_passed_to_pmap)/jit(main)/transpose(jvp(grid2mesh_gnn))/_process/grid2mesh_gnn/_process_step/grid2mesh_gnn/sequential_3/processor_edges_0_grid2mesh_mlp/linear_0/convert_element_type[new_dtype=float32 weak_type=False]\" source_file=\"/home/monte.flora/python_packages/frdd-wofs-cast/wofscast/casting.py\" source_line=197} failed. Falling back to default algorithm.  Per-algorithm errors:\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:35\u001b[0m\n",
      "File \u001b[0;32m~/python_packages/frdd-wofs-cast/wofscast/xarray_jax.py:599\u001b[0m, in \u001b[0;36mpmap.<locals>.result_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m input_treedef\n\u001b[1;32m    598\u001b[0m flat_args, input_treedef \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_flatten(args)\n\u001b[0;32m--> 599\u001b[0m flat_result \u001b[38;5;241m=\u001b[39m \u001b[43mpmapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m output_treedef \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# After the pmap an extra leading axis will be present, we need to add an\u001b[39;00m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# xarray dimension for this when unflattening the result:\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "File \u001b[0;32m/work/mflora/miniconda3/envs/wofs-cast/lib/python3.10/site-packages/jax/_src/compiler.py:236\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(built_c, compile_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    232\u001b[0m                          host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: INTERNAL: All algorithms tried for %convert.411 = f32[192,64]{1,0} convert(bf16[192,64]{1,0} %dot.409), metadata={op_name=\"pmap(fn_passed_to_pmap)/jit(main)/transpose(jvp(grid2mesh_gnn))/_process/grid2mesh_gnn/_process_step/grid2mesh_gnn/sequential_3/processor_edges_0_grid2mesh_mlp/linear_0/convert_element_type[new_dtype=float32 weak_type=False]\" source_file=\"/home/monte.flora/python_packages/frdd-wofs-cast/wofscast/casting.py\" source_line=197} failed. Falling back to default algorithm.  Per-algorithm errors:\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_params, state = init_jitted(\n",
    "    rng=jax.random.PRNGKey(0),\n",
    "    inputs=train_inputs,\n",
    "    targets_template=train_targets,\n",
    "    forcings=train_forcings)\n",
    "\n",
    "\n",
    "# For multiple GPUs!!\n",
    "base_path = '/work/mflora/wofs-cast-data/model'\n",
    "params_path = os.path.join(base_path, 'params.npz')\n",
    "\n",
    "lr = 1e-3\n",
    "optimiser = optax.adam(lr, b1=0.9, b2=0.95, eps=1e-8)\n",
    "\n",
    "# Training loop with linearly increasing learning rate\n",
    "for epoch in range(TOTAL_LINEAR_EPOCHS): \n",
    "    if epoch == 0:\n",
    "        # Initialize the optimizer state only at the beginning\n",
    "        opt_state = optimiser.init(model_params)\n",
    "    \n",
    "    # Create mini-batches for the current epoch and compute gradients. \n",
    "    losses_per_epoch = []\n",
    "    for batch_inputs, batch_targets, batch_forcings in get_random_batches(train_inputs, \n",
    "                                                                          train_targets, \n",
    "                                                                          train_forcings, \n",
    "                                                                          BATCH_SIZE):\n",
    "        \n",
    "        batch_inputs_sharded = shard_xarray_dataset(batch_inputs)\n",
    "        batch_targets_sharded = shard_xarray_dataset(batch_targets)\n",
    "        batch_forcings_sharded = shard_xarray_dataset(batch_forcings)\n",
    "        \n",
    "        model_params_sharded = replicate_for_devices(model_params, num_devices)\n",
    "        state_sharded = replicate_for_devices(state, num_devices)\n",
    "\n",
    "        grads, loss, diagnostics = train_step_pmap(model_params_sharded, \n",
    "                                                   state_sharded, \n",
    "                                                   batch_inputs_sharded, \n",
    "                                                   batch_targets_sharded, \n",
    "                                                   batch_forcings_sharded, \n",
    "                                                  )\n",
    "        \n",
    "        # Aggregate gradients from all devices and apply them \n",
    "        # If your training logic requires aggregation like averaging\n",
    "        grads_avg = jax.tree_map(lambda x: jnp.mean(x, axis=0), grads)\n",
    "\n",
    "        model_params, opt_state = update_step(optimiser, model_params, grads_avg, opt_state)\n",
    "        \n",
    "        losses_per_epoch.append(np.mean(loss))\n",
    "        \n",
    "    print(f\"Epoch: {epoch}.....Loss: {np.mean(losses_per_epoch):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4716b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_mesh_node=array([8321]), node_features.shape=(8321, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:17:39.822227: E external/xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  %compare.6845 = pred[638518,1]{1,0} compare(s32[638518,1]{1,0} %constant.265, s32[638518,1]{1,0} %broadcast.225), direction=GE, metadata={op_name=\"jit(<unnamed wrapped function>)/jit(main)/transpose(jvp(grid2mesh_gnn))/_process/grid2mesh_gnn/_process_step/grid2mesh_gnn/ge\" source_file=\"/home/monte.flora/python_packages/frdd-wofs-cast/wofscast/deep_typed_graph_net.py\" source_line=219}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-02-29 11:17:39.972324: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.150160875s\n",
      "Constant folding an instruction is taking > 2s:\n",
      "\n",
      "  %compare.6845 = pred[638518,1]{1,0} compare(s32[638518,1]{1,0} %constant.265, s32[638518,1]{1,0} %broadcast.225), direction=GE, metadata={op_name=\"jit(<unnamed wrapped function>)/jit(main)/transpose(jvp(grid2mesh_gnn))/_process/grid2mesh_gnn/_process_step/grid2mesh_gnn/ge\" source_file=\"/home/monte.flora/python_packages/frdd-wofs-cast/wofscast/deep_typed_graph_net.py\" source_line=219}\n",
      "\n",
      "This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.\n",
      "\n",
      "If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "2024-02-29 11:17:54.965857: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:17:54.965916: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:54.965923: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:54.965926: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:17:54.965929: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:54.965932: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:54.965935: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:54.965938: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:17:54.965941: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:54.965943: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:54.965946: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:55.450817: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:17:55.450860: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:55.450864: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:55.450868: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:17:55.450871: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:55.450874: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:55.450877: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:55.450879: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:17:55.450882: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:55.450885: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:55.450890: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:56.356621: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:17:56.356672: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:56.356676: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:56.356680: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:17:56.356683: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:56.356686: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:56.356689: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:56.356693: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:17:56.356696: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:56.356698: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:56.356701: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:17:59.238235: W external/xla/xla/service/gpu/triton_autotuner.cc:788] Slow kernel for triton_gemm_dot.247 took: 1.451119629s. config: {block_m:16,block_n:64,block_k:128,split_k:1,num_stages:1,num_warps:4}\n",
      "2024-02-29 11:17:59.238633: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:17:59.238640: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:59.238643: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:59.238646: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:17:59.238649: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:59.238652: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:59.238655: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:59.238658: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:17:59.238661: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:59.238663: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:17:59.238666: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:18:00.188214: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:00.188255: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:00.188259: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:00.188262: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:00.188264: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:00.188267: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:00.188270: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:00.188273: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:00.188276: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:00.188278: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:00.188281: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:01.478185: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:01.478237: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:01.478243: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:01.478246: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:01.478249: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:01.478251: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:01.478254: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:01.478257: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:01.478260: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:01.478262: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:01.478265: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:02.628685: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:02.628726: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:02.628730: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:02.628733: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:02.628735: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:02.628738: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:02.628741: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:02.628744: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:02.628747: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:02.628750: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:02.628753: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:04.811862: W external/xla/xla/service/gpu/triton_autotuner.cc:788] Slow kernel for triton_gemm_dot.247 took: 1.086948364s. config: {block_m:64,block_n:32,block_k:64,split_k:1,num_stages:2,num_warps:8}\n",
      "2024-02-29 11:18:04.812256: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:04.812262: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:04.812265: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:04.812268: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:04.812271: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:04.812274: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:04.812277: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:04.812280: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:04.812282: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:04.812285: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:04.812288: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:05.576584: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:05.576619: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:05.576622: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:05.576625: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:05.576628: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:05.576631: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:05.576634: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:05.576637: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:05.576640: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:05.576642: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:05.576645: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:06.838131: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:06.838177: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:06.838182: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:06.838185: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:06.838188: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:06.838190: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:06.838193: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:06.838196: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:06.838199: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:06.838201: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:06.838205: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:18:09.071472: W external/xla/xla/service/gpu/triton_autotuner.cc:788] Slow kernel for triton_gemm_dot.247 took: 1.116436523s. config: {block_m:64,block_n:64,block_k:64,split_k:1,num_stages:2,num_warps:4}\n",
      "2024-02-29 11:18:09.071953: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:09.071960: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.071963: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.071966: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:09.071969: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.071972: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.071976: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.071978: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:09.071981: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.071984: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.071987: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:09.892016: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:09.892057: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.892060: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.892063: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:09.892066: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.892069: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.892072: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.892075: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:09.892077: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.892080: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:09.892083: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:10.628178: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:10.628230: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:10.628234: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:10.628237: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:10.628240: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:10.628242: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:10.628245: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:10.628248: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:10.628251: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:10.628254: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:10.628257: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:11.513671: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:11.513711: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:11.513714: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:11.513717: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:11.513720: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:11.513723: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:11.513725: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:11.513728: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:11.513731: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:11.513734: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:11.513737: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:13.646444: W external/xla/xla/service/gpu/triton_autotuner.cc:788] Slow kernel for triton_gemm_dot.247 took: 1.066242065s. config: {block_m:128,block_n:64,block_k:32,split_k:1,num_stages:3,num_warps:8}\n",
      "2024-02-29 11:18:13.646840: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:13.646846: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:13.646849: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:13.646852: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:13.646855: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:13.646858: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:13.646861: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:13.646864: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:13.646867: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:13.646869: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:13.646872: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:15.092575: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:15.092619: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:15.092623: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:15.092626: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:15.092629: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:15.092631: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:15.092634: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:15.092637: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:15.092640: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:15.092643: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:15.092645: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:18:16.248283: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:16.248325: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:16.248328: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:16.248331: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:16.248334: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:16.248337: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:16.248339: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:16.248342: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:16.248345: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:16.248348: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:16.248351: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:17.967501: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 1.40247e+07, expected 2.0054e+07\n",
      "2024-02-29 11:18:17.967540: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 1.38936e+07, expected 1.99229e+07\n",
      "2024-02-29 11:18:17.967543: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 1.38281e+07, expected 1.99229e+07\n",
      "2024-02-29 11:18:17.967546: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 1.3697e+07, expected 1.96608e+07\n",
      "2024-02-29 11:18:17.967549: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 1.38936e+07, expected 1.99229e+07\n",
      "2024-02-29 11:18:17.967552: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 1.38936e+07, expected 1.99229e+07\n",
      "2024-02-29 11:18:17.967555: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 1.38281e+07, expected 1.99229e+07\n",
      "2024-02-29 11:18:17.967558: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 1.39592e+07, expected 2.0054e+07\n",
      "2024-02-29 11:18:17.967561: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 1.38281e+07, expected 1.99229e+07\n",
      "2024-02-29 11:18:17.967563: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 1.38936e+07, expected 1.99229e+07\n",
      "2024-02-29 11:18:17.967566: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:19.179629: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:19.179679: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:19.179682: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:19.179685: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:19.179688: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:19.179691: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:19.179694: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:19.179697: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:19.179699: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:19.179702: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:19.179705: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:21.812210: W external/xla/xla/service/gpu/triton_autotuner.cc:788] Slow kernel for triton_gemm_dot.247 took: 1.317093383s. config: {block_m:256,block_n:64,block_k:32,split_k:1,num_stages:3,num_warps:8}\n",
      "2024-02-29 11:18:21.812623: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:21.812629: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:21.812632: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:21.812635: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:21.812638: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:21.812641: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:21.812644: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:21.812647: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:21.812649: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:21.812652: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:21.812655: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:24.056200: W external/xla/xla/service/gpu/triton_autotuner.cc:788] Slow kernel for triton_gemm_dot.247 took: 1.121658935s. config: {block_m:256,block_n:64,block_k:32,split_k:1,num_stages:4,num_warps:4}\n",
      "2024-02-29 11:18:24.056609: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:24.056615: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:24.056618: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:24.056621: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:24.056624: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:24.056627: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:24.056629: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:24.056632: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:24.056635: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:24.056638: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:24.056640: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "2024-02-29 11:18:26.217552: W external/xla/xla/service/gpu/triton_autotuner.cc:788] Slow kernel for triton_gemm_dot.247 took: 1.080301513s. config: {block_m:256,block_n:64,block_k:128,split_k:1,num_stages:3,num_warps:8}\n",
      "2024-02-29 11:18:26.218019: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 0: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:26.218025: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 1: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:26.218028: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 2: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:26.218031: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 3: 9.69933e+06, expected 1.96608e+07\n",
      "2024-02-29 11:18:26.218034: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 4: 9.89594e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:26.218037: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 5: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:26.218039: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 6: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:26.218042: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 7: 9.89594e+06, expected 2.0054e+07\n",
      "2024-02-29 11:18:26.218045: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 8: 9.76486e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:26.218048: E external/xla/xla/service/gpu/buffer_comparator.cc:149] Difference at 9: 9.8304e+06, expected 1.99229e+07\n",
      "2024-02-29 11:18:26.218051: E external/xla/xla/service/gpu/triton_autotuner.cc:816] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "INTERNAL: All algorithms tried for %convert.411 = f32[192,64]{1,0} convert(bf16[192,64]{1,0} %dot.409), metadata={op_name=\"jit(<unnamed wrapped function>)/jit(main)/transpose(jvp(grid2mesh_gnn))/_process/grid2mesh_gnn/_process_step/grid2mesh_gnn/sequential_3/processor_edges_0_grid2mesh_mlp/linear_0/convert_element_type[new_dtype=float32 weak_type=False]\" source_file=\"/home/monte.flora/python_packages/frdd-wofs-cast/wofscast/casting.py\" source_line=197} failed. Falling back to default algorithm.  Per-algorithm errors:\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:24\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m/work/mflora/miniconda3/envs/wofs-cast/lib/python3.10/site-packages/jax/_src/compiler.py:236\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(built_c, compile_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    232\u001b[0m                          host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: INTERNAL: All algorithms tried for %convert.411 = f32[192,64]{1,0} convert(bf16[192,64]{1,0} %dot.409), metadata={op_name=\"jit(<unnamed wrapped function>)/jit(main)/transpose(jvp(grid2mesh_gnn))/_process/grid2mesh_gnn/_process_step/grid2mesh_gnn/sequential_3/processor_edges_0_grid2mesh_mlp/linear_0/convert_element_type[new_dtype=float32 weak_type=False]\" source_file=\"/home/monte.flora/python_packages/frdd-wofs-cast/wofscast/casting.py\" source_line=197} failed. Falling back to default algorithm.  Per-algorithm errors:\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision.\n  Results do not match the reference. This is likely a bug/unexpected loss of precision."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_params, state = init_jitted(\n",
    "    rng=jax.random.PRNGKey(0),\n",
    "    inputs=train_inputs,\n",
    "    targets_template=train_targets,\n",
    "    forcings=train_forcings)\n",
    "\n",
    "# remove `with_params` from jitted grads function\n",
    "grads_fn_jitted = jax.jit(with_configs(train_step))\n",
    "\n",
    "lr = 1e-3\n",
    "optimiser = optax.adam(lr, b1=0.9, b2=0.95, eps=1e-8)\n",
    "\n",
    "# Training loop with linearly increasing learning rate\n",
    "for epoch in range(TOTAL_LINEAR_EPOCHS): \n",
    "    if epoch == 0:\n",
    "        # Initialize the optimizer state only at the beginning\n",
    "        opt_state = optimiser.init(model_params)\n",
    "    \n",
    "    # Create mini-batches for the current epoch and compute gradients. \n",
    "    losses_per_epoch = []\n",
    "    for batch_inputs, batch_targets, batch_forcings in get_random_batches(train_inputs, train_targets, \n",
    "                                                                          train_forcings, \n",
    "                                                                          BATCH_SIZE):\n",
    "        grads, loss, diagnostics = grads_fn_jitted(model_params, state, batch_inputs, \n",
    "                                                           batch_targets, batch_forcings)\n",
    "        losses_per_epoch.append(loss)\n",
    "        \n",
    "        # Update parameters\n",
    "        model_params, opt_state = update_step(optimiser, model_params, grads, opt_state)\n",
    "\n",
    "    print(f\"Epoch: {epoch}.....Loss: {np.mean(losses_per_epoch):.5f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21e527ec",
   "metadata": {},
   "source": [
    "# For a single GPU\n",
    "\n",
    "from jax import tree_util\n",
    "\n",
    "# Define the gradient function\n",
    "def grads_fn(params, state, inputs, targets, forcings, model_config, task_config):\n",
    "    def compute_loss(params, state, inputs, targets, forcings):\n",
    "        (loss, diagnostics), next_state = loss_fn.apply(params, state, \n",
    "                                                        jax.random.PRNGKey(0), \n",
    "                                                        model_config, \n",
    "                                                        task_config, \n",
    "                                                        inputs, targets, forcings)\n",
    "        return loss, (diagnostics, next_state)\n",
    "    \n",
    "    # Compute gradients and auxiliary outputs\n",
    "    (loss, (diagnostics, next_state)), grads = jax.value_and_grad(compute_loss, has_aux=True)(params, state, \n",
    "                                                                                              inputs, targets, \n",
    "                                                                                              forcings)\n",
    "    \n",
    "    # Compute the global norm of all gradients\n",
    "    total_norm = jnp.sqrt(sum(jnp.sum(jnp.square(g)) for g in tree_util.tree_leaves(grads)))\n",
    "\n",
    "    # Clip gradients if the total norm exceeds the threshold\n",
    "    def clip_grads(g, clip_norm=32):\n",
    "        return jnp.where(total_norm > clip_norm, g * clip_norm / total_norm, g)\n",
    "\n",
    "    clipped_grads = tree_util.tree_map(clip_grads, grads)\n",
    "\n",
    "    \n",
    "    return loss, diagnostics, next_state, grads\n",
    "\n",
    "# remove `with_params` from jitted grads function\n",
    "grads_fn_jitted = jax.jit(with_configs(grads_fn))\n",
    "\n",
    "\n",
    "def get_random_batches(inputs, targets, forcings, batch_size):\n",
    "    total_samples = inputs.dims['batch']\n",
    "    indices = np.arange(total_samples)\n",
    "    np.random.shuffle(indices)  # Randomly shuffle the indices\n",
    "\n",
    "    for start_idx in range(0, total_samples, batch_size):\n",
    "        end_idx = min(start_idx + batch_size, total_samples)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        yield (inputs.isel(batch=batch_indices), \n",
    "               targets.isel(batch=batch_indices), \n",
    "               forcings.isel(batch=batch_indices))\n",
    "\n",
    "# Training Parameters. \n",
    "TOTAL_LINEAR_EPOCHS = 10\n",
    "TOTAL_COSINE_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "checkpoint = False\n",
    "\n",
    "# Setup the learning rate schedule\n",
    "start_learning_rate = 1e-6  # Start from 0\n",
    "end_learning_rate = 1e-3  # Increase to 1e-3\n",
    "schedule = optax.linear_schedule(init_value=start_learning_rate, \n",
    "                                 end_value=end_learning_rate, \n",
    "                                 transition_steps=TOTAL_LINEAR_EPOCHS)\n",
    "\n",
    "base_path = '/work/mflora/wofs-cast-data/model'\n",
    "params_path = os.path.join(base_path, 'params.npz')\n",
    "\n",
    "\n",
    "# Training loop with linearly increasing learning rate\n",
    "for epoch in range(TOTAL_LINEAR_EPOCHS): \n",
    "    # Get the current learning rate from the schedule\n",
    "    lr = schedule(epoch)\n",
    "    # Setup optimizer with the current learning rate\n",
    "    optimiser = optax.adam(lr, b1=0.9, b2=0.95, eps=1e-8)\n",
    "    if epoch == 0:\n",
    "        # Initialize the optimizer state only at the beginning\n",
    "        opt_state = optimiser.init(model_params)\n",
    "    \n",
    "    # Create mini-batches for the current epoch and compute gradients. \n",
    "    losses_per_epoch = []\n",
    "    for batch_inputs, batch_targets, batch_forcings in get_random_batches(train_inputs, train_targets, \n",
    "                                                                          train_forcings, \n",
    "                                                                          BATCH_SIZE):\n",
    "        loss, diagnostics, next_state, grads = grads_fn_jitted(model_params, state, batch_inputs, \n",
    "                                                           batch_targets, batch_forcings)\n",
    "        losses_per_epoch.append(loss)\n",
    "        \n",
    "        # Update parameters\n",
    "        updates, opt_state = optimiser.update(grads, opt_state)\n",
    "        model_params = optax.apply_updates(model_params, updates)\n",
    "    \n",
    "    # Every 50 epoches, save the model_params\n",
    "    if epoch % 50 == 0 and checkpoint:\n",
    "        print('Saving model params....')\n",
    "        save_model_params(model_params, params_path)\n",
    "            \n",
    "    \n",
    "    print(f\"Epoch: {epoch}.....Loss: {np.mean(losses_per_epoch):.5f}\")\n",
    "    \n",
    "        \n",
    "# Initialize the cosine decay schedule from Optax\n",
    "cosine_schedule = optax.cosine_decay_schedule(init_value=1e-3, \n",
    "                                                  decay_steps=TOTAL_COSINE_EPOCHS, \n",
    "                                                  alpha=0)  # alpha=0 makes it decay to 0        \n",
    "\n",
    "# Training loop with decaying learning rate\n",
    "for epoch in range(TOTAL_COSINE_EPOCHS): \n",
    "    # Get the current learning rate from the schedule\n",
    "    lr = cosine_schedule(epoch)\n",
    "    # Setup optimizer with the current learning rate\n",
    "    optimiser = optax.adam(lr, b1=0.9, b2=0.95, eps=1e-8)\n",
    "\n",
    "    # Create mini-batches for the current epoch and compute gradients. \n",
    "    losses_per_epoch = []\n",
    "    for batch_inputs, batch_targets, batch_forcings in get_random_batches(train_inputs, train_targets, \n",
    "                                                                          train_forcings, \n",
    "                                                                          BATCH_SIZE):\n",
    "        loss, diagnostics, next_state, grads = grads_fn_jitted(model_params, state, batch_inputs, \n",
    "                                                           batch_targets, batch_forcings)\n",
    "        losses_per_epoch.append(loss)\n",
    "        \n",
    "        # Update parameters\n",
    "        updates, opt_state = optimiser.update(grads, opt_state)\n",
    "        model_params = optax.apply_updates(model_params, updates) \n",
    "        \n",
    "    print(f\"Epoch: {epoch}.....Loss: {np.mean(losses_per_epoch):.5f}\")\n",
    "    \n",
    "    \n",
    "    # Every 50 epoches, save the model_params\n",
    "    if epoch % 1000 == 0 and checkpoint:\n",
    "        print('Saving model params....')\n",
    "        save_model_params(model_params, params_path)\n",
    "        \n",
    "        \n",
    "#TODO: Final training schedule for longer predictions. Increasing timesteps every 1000\n",
    "# epoches with a fixed learning rate of 3e-7 (really low, but for fine tuning.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6afedc08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diagnostics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdiagnostics\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'diagnostics' is not defined"
     ]
    }
   ],
   "source": [
    "diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe11654",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_params(model_params, params_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59129414",
   "metadata": {},
   "source": [
    "### Run the model forward based on the new model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always pass params and state, so the usage below are simpler\n",
    "def with_model_params(fn):\n",
    "  return functools.partial(fn, params=model_params, state=state)\n",
    "\n",
    "run_forward_jitted = drop_state(with_model_params(jax.jit(with_configs(\n",
    "    run_forward.apply))))\n",
    "\n",
    "# @title Autoregressive rollout (keep the loop in JAX)\n",
    "print(\"Inputs:  \", eval_inputs.dims.mapping)\n",
    "print(\"Targets: \", eval_targets.dims.mapping)\n",
    "print(\"Forcings:\", eval_forcings.dims.mapping)\n",
    "\n",
    "predictions = rollout.chunked_prediction(\n",
    "    run_forward_jitted,\n",
    "    rng=jax.random.PRNGKey(0),\n",
    "    inputs=eval_inputs,\n",
    "    targets_template=eval_targets * np.nan,\n",
    "    forcings=eval_forcings)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "preds =  predictions.squeeze(dim='batch', drop=True)\n",
    "targets = eval_targets.squeeze(dim='batch', drop=True)\n",
    "\n",
    "#print(np.max(preds['T'][1] - preds['T'][1]))\n",
    "#print(np.max(targets['T'][0] - targets['T'][0]))\n",
    "\n",
    "var = 'U'\n",
    "\n",
    "def get_target_and_pred_pair(preds, targets, t, level=0):\n",
    "    # (time, level, lat, lon )\n",
    "    if level == 'max':\n",
    "        zs = [targets[var][t].max(dim='level').values, preds[var][t].max(dim='level').values]\n",
    "    elif level == 'min': \n",
    "        zs = [targets[var][t].min(dim='level').values, preds[var][t].min(dim='level').values]\n",
    "    elif level == 'none':\n",
    "        zs = [targets[var][t].values, preds[var][t].values]\n",
    "    else:\n",
    "        zs = [targets[var][t, level].values, preds[var][t, level].values]\n",
    "    return zs \n",
    "\n",
    "fig, axes = plt.subplots(dpi=200, figsize=(10,6), ncols=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "zs = get_target_and_pred_pair(preds, targets, t=0)\n",
    "\n",
    "titles = ['Target', 'Prediction']\n",
    "for i, (ax, z) in enumerate(zip(axes, zs)):\n",
    "    div = make_axes_locatable(ax)\n",
    "    cax = div.append_axes('right', '5%', '5%')\n",
    "    if var in ['REFL_10CM', 'UP_HELI_MAX']:\n",
    "        z = np.ma.masked_where(z<5,z)\n",
    "    \n",
    "    im = ax.imshow(z, origin='lower', aspect='equal', cmap='jet')\n",
    "    cb = fig.colorbar(im, cax=cax)\n",
    "    ax.set_title(titles[i])\n",
    "    \n",
    "# This function will update the content of the plot for each frame\n",
    "def update(t):\n",
    "    # Clear the current axes\n",
    "    for ax in axes:\n",
    "        ax.clear()\n",
    "\n",
    "    zs = get_target_and_pred_pair(preds, targets, t=t)\n",
    "    \n",
    "    titles = ['Target', 'Prediction']\n",
    "    for i, (ax, z) in enumerate(zip(axes, zs)):\n",
    "        if var in ['REFL_10CM', 'UP_HELI_MAX']:\n",
    "            z = np.ma.masked_where(z<5,z)\n",
    "        im = ax.imshow(z, origin='lower', aspect='equal', cmap='jet')\n",
    "        ax.set_title(titles[i])\n",
    "\n",
    "\n",
    "# Total number of frames (adjust 'N' according to the size of your data along the 't' dimension)\n",
    "N = targets[var].shape[0]  # Assuming the second dimension is 't'\n",
    "\n",
    "# Create animation\n",
    "anim = FuncAnimation(fig, update, frames=N, interval=200)  # Adjust interval for frame speed\n",
    "\n",
    "# To display the animation in a Jupyter notebook\n",
    "from IPython.display import HTML\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d3c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
