{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b4de7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 15:49:00.655342: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-19 15:49:00.679689: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-19 15:49:00.679722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-19 15:49:00.680325: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-19 15:49:00.684512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-19 15:49:01.539280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ModelConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Any variables not specified here are weighted as 1.0.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# A single-level variable, but an important headline variable\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# and also one which we have struggled to get good performance\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Lower weight = less important of loss\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     45\u001b[0m PER_VARIABLE_WEIGHTS \u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m1.0\u001b[39m}\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGraphCast\u001b[39;00m(predictor_base\u001b[38;5;241m.\u001b[39mPredictor):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"GraphCast Predictor.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m  The model works on graphs that take into account:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_config: ModelConfig, task_config: TaskConfig, loss_weights: \u001b[38;5;28mdict\u001b[39m, vars_2D: \u001b[38;5;28mlist\u001b[39m):\n",
      "Cell \u001b[0;32mIn[2], line 78\u001b[0m, in \u001b[0;36mGraphCast\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGraphCast\u001b[39;00m(predictor_base\u001b[38;5;241m.\u001b[39mPredictor):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"GraphCast Predictor.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m  The model works on graphs that take into account:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_config: \u001b[43mModelConfig\u001b[49m, task_config: TaskConfig, loss_weights: \u001b[38;5;28mdict\u001b[39m, vars_2D: \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes the predictor.\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_features_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     81\u001b[0m         add_node_positions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     82\u001b[0m         add_node_latitude\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m         relative_latitude_local_coordinates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ModelConfig' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"A predictor that runs multiple graph neural networks on mesh data.\n",
    "\n",
    "It learns to interpolate between the grid and the mesh nodes, with the loss\n",
    "and the rollouts ultimately computed at the grid level.\n",
    "\n",
    "Refactored version of the GraphCast code (https://github.com/google-deepmind/graphcast) \n",
    "to use the tensorflow-gnn GraphTensor. \n",
    "\n",
    "It assumes data across time and level is stacked, and operates only operates in\n",
    "a 2D mesh over latitudes and longitudes.\n",
    "\"\"\"\n",
    "import sys, os \n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "from typing import Any, Callable, Mapping, Optional\n",
    "\n",
    "\n",
    "\n",
    "from wofscast import encode_process_decode \n",
    "from wofscast import grid_mesh_connectivity\n",
    "from wofscast import icosahedral_mesh\n",
    "from wofscast import losses\n",
    "from wofscast import model_utils\n",
    "from wofscast import predictor_base\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xarray\n",
    "\n",
    "Kwargs = Mapping[str, Any]\n",
    "\n",
    "\n",
    "# Any variables not specified here are weighted as 1.0.\n",
    "# A single-level variable, but an important headline variable\n",
    "# and also one which we have struggled to get good performance\n",
    "# on at short lead times, so leaving it weighted at 1.0, equal\n",
    "# to the multi-level variables:\n",
    "\n",
    "# New single-level variables, which we don't weight too highly\n",
    "# to avoid hurting performance on other variables. \n",
    "# Lower weight = less important of loss\n",
    "# \n",
    "PER_VARIABLE_WEIGHTS ={'T' : 1.0, 'P' : 1.0}\n",
    "\n",
    "\n",
    "class GraphCast(predictor_base.Predictor):\n",
    "  \"\"\"GraphCast Predictor.\n",
    "\n",
    "  The model works on graphs that take into account:\n",
    "  * Mesh nodes: nodes for the vertices of the mesh.\n",
    "  * Grid nodes: nodes for the points of the grid.\n",
    "  * Nodes: When referring to just \"nodes\", this means the joint set of\n",
    "    both mesh nodes, concatenated with grid nodes.\n",
    "\n",
    "  The model works with 3 graphs:\n",
    "  * Grid2Mesh graph: Graph that contains all nodes. This graph is strictly\n",
    "    bipartite with edges going from grid nodes to mesh nodes using a\n",
    "    fixed radius query. The grid2mesh_gnn will operate in this graph. The output\n",
    "    of this stage will be a latent representation for the mesh nodes, and a\n",
    "    latent representation for the grid nodes.\n",
    "  * Mesh graph: Graph that contains mesh nodes only. The mesh_gnn will\n",
    "    operate in this graph. It will update the latent state of the mesh nodes\n",
    "    only.\n",
    "  * Mesh2Grid graph: Graph that contains all nodes. This graph is strictly\n",
    "    bipartite with edges going from mesh nodes to grid nodes such that each grid\n",
    "    nodes is connected to 3 nodes of the mesh triangular face that contains\n",
    "    the grid points. The mesh2grid_gnn will operate in this graph. It will\n",
    "    process the updated latent state of the mesh nodes, and the latent state\n",
    "    of the grid nodes, to produce the final output for the grid nodes.\n",
    "\n",
    "  The model is built on top of `TypedGraph`s so the different types of nodes and\n",
    "  edges can be stored and treated separately.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, model_config: ModelConfig, task_config: TaskConfig, loss_weights: dict, vars_2D: list):\n",
    "    \"\"\"Initializes the predictor.\"\"\"\n",
    "    self._spatial_features_kwargs = dict(\n",
    "        add_node_positions=False,\n",
    "        add_node_latitude=True,\n",
    "        add_node_longitude=True,\n",
    "        add_relative_positions=True,\n",
    "        relative_longitude_local_coordinates=True,\n",
    "        relative_latitude_local_coordinates=True,\n",
    "    )\n",
    "    self._loss_weights = loss_weights\n",
    "\n",
    "\n",
    "    # Specification of the multimesh.\n",
    "    self._meshes = (\n",
    "        icosahedral_mesh.get_hierarchy_of_triangular_meshes_for_sphere(\n",
    "            splits=model_config.mesh_size))\n",
    "\n",
    "    # Encoder, which moves data from the grid to the mesh with a single message\n",
    "    # passing step.\n",
    "    self._grid2mesh_gnn = deep_typed_graph_net.DeepTypedGraphNet(\n",
    "        embed_nodes=True,  # Embed raw features of the grid and mesh nodes.\n",
    "        embed_edges=True,  # Embed raw features of the grid2mesh edges.\n",
    "        edge_latent_size=dict(grid2mesh=model_config.latent_size),\n",
    "        node_latent_size=dict(\n",
    "            mesh_nodes=model_config.latent_size,\n",
    "            grid_nodes=model_config.latent_size),\n",
    "        mlp_hidden_size=model_config.latent_size,\n",
    "        mlp_num_hidden_layers=model_config.hidden_layers,\n",
    "        num_message_passing_steps=1,\n",
    "        use_layer_norm=True,\n",
    "        include_sent_messages_in_node_update=False,\n",
    "        activation=\"swish\",\n",
    "        f32_aggregation=True,\n",
    "        aggregate_normalization=None,\n",
    "        name=\"grid2mesh_gnn\",\n",
    "    )\n",
    "\n",
    "    # Processor, which performs message passing on the multi-mesh.\n",
    "    self._mesh_gnn = deep_typed_graph_net.DeepTypedGraphNet(\n",
    "        embed_nodes=False,  # Node features already embdded by previous layers.\n",
    "        embed_edges=True,  # Embed raw features of the multi-mesh edges.\n",
    "        node_latent_size=dict(mesh_nodes=model_config.latent_size),\n",
    "        edge_latent_size=dict(mesh=model_config.latent_size),\n",
    "        mlp_hidden_size=model_config.latent_size,\n",
    "        mlp_num_hidden_layers=model_config.hidden_layers,\n",
    "        num_message_passing_steps=model_config.gnn_msg_steps,\n",
    "        use_layer_norm=True,\n",
    "        include_sent_messages_in_node_update=False,\n",
    "        activation=\"swish\",\n",
    "        f32_aggregation=False,\n",
    "        name=\"mesh_gnn\",\n",
    "    )\n",
    "    \n",
    "    # Print\n",
    "    n_levels = len(task_config.pressure_levels) \n",
    "    n_vars = len(set(task_config.target_variables))\n",
    "    n_vars_2D = len(vars_2D)\n",
    "    n_vars_3D = n_vars - n_vars_2D\n",
    "          \n",
    "    ##print(f'{n_levels=}, {n_vars=}, {n_vars_2D=}, {n_vars_3D=}')\n",
    "    \n",
    "    num_outputs = n_vars_2D + (n_levels * n_vars_3D)\n",
    "    \n",
    "    #num_outputs = (num_surface_vars + n_levels * num_atmospheric_vars)\n",
    "    \n",
    "    #num_surface_vars = len(\n",
    "    #    set(task_config.target_variables) - set(ALL_ATMOSPHERIC_VARS))\n",
    "    #num_atmospheric_vars = len(\n",
    "    #    set(task_config.target_variables) & set(ALL_ATMOSPHERIC_VARS))\n",
    "    #num_outputs = (num_surface_vars +\n",
    "    #               len(task_config.pressure_levels) * num_atmospheric_vars)\n",
    "\n",
    "    # Decoder, which moves data from the mesh back into the grid with a single\n",
    "    # message passing step.\n",
    "    self._mesh2grid_gnn = deep_typed_graph_net.DeepTypedGraphNet(\n",
    "        # Require a specific node dimensionaly for the grid node outputs.\n",
    "        node_output_size=dict(grid_nodes=num_outputs),\n",
    "        embed_nodes=False,  # Node features already embdded by previous layers.\n",
    "        embed_edges=True,  # Embed raw features of the mesh2grid edges.\n",
    "        edge_latent_size=dict(mesh2grid=model_config.latent_size),\n",
    "        node_latent_size=dict(\n",
    "            mesh_nodes=model_config.latent_size,\n",
    "            grid_nodes=model_config.latent_size),\n",
    "        mlp_hidden_size=model_config.latent_size,\n",
    "        mlp_num_hidden_layers=model_config.hidden_layers,\n",
    "        num_message_passing_steps=1,\n",
    "        use_layer_norm=True,\n",
    "        include_sent_messages_in_node_update=False,\n",
    "        activation=\"swish\",\n",
    "        f32_aggregation=False,\n",
    "        name=\"mesh2grid_gnn\",\n",
    "    )\n",
    "\n",
    "    # Obtain the query radius in absolute units for the unit-sphere for the\n",
    "    # grid2mesh model, by rescaling the `radius_query_fraction_edge_length`.\n",
    "    self._query_radius = (_get_max_edge_distance(self._finest_mesh)\n",
    "                          * model_config.radius_query_fraction_edge_length)\n",
    "    self._mesh2grid_edge_normalization_factor = (\n",
    "        model_config.mesh2grid_edge_normalization_factor\n",
    "    )\n",
    "\n",
    "    # Other initialization is delayed until the first call (`_maybe_init`)\n",
    "    # when we get some sample data so we know the lat/lon values.\n",
    "    self._initialized = False\n",
    "\n",
    "    # A \"_init_mesh_properties\":\n",
    "    # This one could be initialized at init but we delay it for consistency too.\n",
    "    self._num_mesh_nodes = None  # num_mesh_nodes\n",
    "    self._mesh_nodes_lat = None  # [num_mesh_nodes]\n",
    "    self._mesh_nodes_lon = None  # [num_mesh_nodes]\n",
    "\n",
    "    # A \"_init_grid_properties\":\n",
    "    self._grid_lat = None  # [num_lat_points]\n",
    "    self._grid_lon = None  # [num_lon_points]\n",
    "    self._num_grid_nodes = None  # num_lat_points * num_lon_points\n",
    "    self._grid_nodes_lat = None  # [num_grid_nodes]\n",
    "    self._grid_nodes_lon = None  # [num_grid_nodes]\n",
    "\n",
    "    # A \"_init_{grid2mesh,processor,mesh2grid}_graph\"\n",
    "    self._grid2mesh_graph_structure = None\n",
    "    self._mesh_graph_structure = None\n",
    "    self._mesh2grid_graph_structure = None\n",
    "\n",
    "  @property\n",
    "  def _finest_mesh(self):\n",
    "    return self._meshes[-1]\n",
    "\n",
    "  def __call__(self,\n",
    "               inputs: xarray.Dataset,\n",
    "               targets_template: xarray.Dataset,\n",
    "               forcings: xarray.Dataset,\n",
    "               is_training: bool = False,\n",
    "               ) -> xarray.Dataset:\n",
    "    self._maybe_init(inputs)\n",
    "\n",
    "    # Convert all input data into flat vectors for each of the grid nodes.\n",
    "    # xarray (batch, time, lat, lon, level, multiple vars, forcings)\n",
    "    # -> [num_grid_nodes, batch, num_channels]\n",
    "    grid_node_features = self._inputs_to_grid_node_features(inputs, forcings)\n",
    "\n",
    "    # Transfer data for the grid to the mesh,\n",
    "    # [num_mesh_nodes, batch, latent_size], [num_grid_nodes, batch, latent_size]\n",
    "    (latent_mesh_nodes, latent_grid_nodes\n",
    "     ) = self._run_grid2mesh_gnn(grid_node_features)\n",
    "\n",
    "    # Run message passing in the multimesh.\n",
    "    # [num_mesh_nodes, batch, latent_size]\n",
    "    updated_latent_mesh_nodes = self._run_mesh_gnn(latent_mesh_nodes)\n",
    "\n",
    "    # Transfer data frome the mesh to the grid.\n",
    "    # [num_grid_nodes, batch, output_size]\n",
    "    output_grid_nodes = self._run_mesh2grid_gnn(\n",
    "        updated_latent_mesh_nodes, latent_grid_nodes)\n",
    "\n",
    "    # Convert output flat vectors for the grid nodes to the format of the output.\n",
    "    # [num_grid_nodes, batch, output_size] ->\n",
    "    # xarray (batch, one time step, lat, lon, level, multiple vars)\n",
    "    return self._grid_node_outputs_to_prediction(\n",
    "        output_grid_nodes, targets_template)\n",
    "\n",
    "  def loss_and_predictions(  # pytype: disable=signature-mismatch  # jax-ndarray\n",
    "      self,\n",
    "      inputs: xarray.Dataset,\n",
    "      targets: xarray.Dataset,\n",
    "      forcings: xarray.Dataset,\n",
    "      ) -> tuple[predictor_base.LossAndDiagnostics, xarray.Dataset]:\n",
    "    # Forward pass.\n",
    "    predictions = self(\n",
    "        inputs, targets_template=targets, forcings=forcings, is_training=True)\n",
    "    \n",
    "    loss = losses.weighted_mse_per_level(\n",
    "        predictions, targets, \n",
    "        per_variable_weights=self._loss_weights\n",
    "       )\n",
    "    return loss, predictions  # pytype: disable=bad-return-type  # jax-ndarray\n",
    "\n",
    "  def loss(  # pytype: disable=signature-mismatch  # jax-ndarray\n",
    "      self,\n",
    "      inputs: xarray.Dataset,\n",
    "      targets: xarray.Dataset,\n",
    "      forcings: xarray.Dataset,\n",
    "      ) -> predictor_base.LossAndDiagnostics:\n",
    "    loss, _ = self.loss_and_predictions(inputs, targets, forcings)\n",
    "    return loss  # pytype: disable=bad-return-type  # jax-ndarray\n",
    "\n",
    "  def _maybe_init(self, sample_inputs: xarray.Dataset):\n",
    "    \"\"\"Inits everything that has a dependency on the input coordinates.\"\"\"\n",
    "    if not self._initialized:\n",
    "      self._init_mesh_properties()\n",
    "      self._init_grid_properties(\n",
    "          grid_lat=sample_inputs.lat, grid_lon=sample_inputs.lon)\n",
    "      self._grid2mesh_graph_structure = self._init_grid2mesh_graph()\n",
    "      self._mesh_graph_structure = self._init_mesh_graph()\n",
    "      self._mesh2grid_graph_structure = self._init_mesh2grid_graph()\n",
    "\n",
    "      self._initialized = True\n",
    "\n",
    "  def _init_mesh_properties(self):\n",
    "    \"\"\"Inits static properties that have to do with mesh nodes.\"\"\"\n",
    "    self._num_mesh_nodes = self._finest_mesh.vertices.shape[0]\n",
    "    mesh_phi, mesh_theta = model_utils.cartesian_to_spherical(\n",
    "        self._finest_mesh.vertices[:, 0],\n",
    "        self._finest_mesh.vertices[:, 1],\n",
    "        self._finest_mesh.vertices[:, 2])\n",
    "    (\n",
    "        mesh_nodes_lat,\n",
    "        mesh_nodes_lon,\n",
    "    ) = model_utils.spherical_to_lat_lon(\n",
    "        phi=mesh_phi, theta=mesh_theta)\n",
    "    # Convert to f32 to ensure the lat/lon features aren't in f64.\n",
    "    self._mesh_nodes_lat = mesh_nodes_lat.astype(np.float32)\n",
    "    self._mesh_nodes_lon = mesh_nodes_lon.astype(np.float32)\n",
    "\n",
    "  def _init_grid_properties(self, grid_lat: np.ndarray, grid_lon: np.ndarray):\n",
    "    \"\"\"Inits static properties that have to do with grid nodes.\"\"\"\n",
    "    self._grid_lat = grid_lat.astype(np.float32)\n",
    "    self._grid_lon = grid_lon.astype(np.float32)\n",
    "    # Initialized the counters.\n",
    "    self._num_grid_nodes = grid_lat.shape[0] * grid_lon.shape[0]\n",
    "\n",
    "    # Initialize lat and lon for the grid.\n",
    "    grid_nodes_lon, grid_nodes_lat = np.meshgrid(grid_lon, grid_lat)\n",
    "    self._grid_nodes_lon = grid_nodes_lon.reshape([-1]).astype(np.float32)\n",
    "    self._grid_nodes_lat = grid_nodes_lat.reshape([-1]).astype(np.float32)\n",
    "\n",
    "  def _init_grid2mesh_graph(self) -> typed_graph.TypedGraph:\n",
    "    \"\"\"Build Grid2Mesh graph.\"\"\"\n",
    "\n",
    "    # Create some edges according to distance between mesh and grid nodes.\n",
    "    assert self._grid_lat is not None and self._grid_lon is not None\n",
    "    (grid_indices, mesh_indices) = grid_mesh_connectivity.radius_query_indices(\n",
    "        grid_latitude=self._grid_lat,\n",
    "        grid_longitude=self._grid_lon,\n",
    "        mesh=self._finest_mesh,\n",
    "        radius=self._query_radius)\n",
    "\n",
    "    # Edges sending info from grid to mesh.\n",
    "    senders = grid_indices\n",
    "    receivers = mesh_indices\n",
    "\n",
    "    # Precompute structural node and edge features according to config options.\n",
    "    # Structural features are those that depend on the fixed values of the\n",
    "    # latitude and longitudes of the nodes.\n",
    "    (senders_node_features, receivers_node_features,\n",
    "     edge_features) = model_utils.get_bipartite_graph_spatial_features(\n",
    "         senders_node_lat=self._grid_nodes_lat,\n",
    "         senders_node_lon=self._grid_nodes_lon,\n",
    "         receivers_node_lat=self._mesh_nodes_lat,\n",
    "         receivers_node_lon=self._mesh_nodes_lon,\n",
    "         senders=senders,\n",
    "         receivers=receivers,\n",
    "         edge_normalization_factor=None,\n",
    "         **self._spatial_features_kwargs,\n",
    "     )\n",
    "\n",
    "    n_grid_node = np.array([self._num_grid_nodes])\n",
    "    n_mesh_node = np.array([self._num_mesh_nodes])\n",
    "    n_edge = np.array([mesh_indices.shape[0]])\n",
    "    grid_node_set = typed_graph.NodeSet(\n",
    "        n_node=n_grid_node, features=senders_node_features)\n",
    "    mesh_node_set = typed_graph.NodeSet(\n",
    "        n_node=n_mesh_node, features=receivers_node_features)\n",
    "    edge_set = typed_graph.EdgeSet(\n",
    "        n_edge=n_edge,\n",
    "        indices=typed_graph.EdgesIndices(senders=senders, receivers=receivers),\n",
    "        features=edge_features)\n",
    "    nodes = {\"grid_nodes\": grid_node_set, \"mesh_nodes\": mesh_node_set}\n",
    "    edges = {\n",
    "        typed_graph.EdgeSetKey(\"grid2mesh\", (\"grid_nodes\", \"mesh_nodes\")):\n",
    "            edge_set\n",
    "    }\n",
    "    grid2mesh_graph = typed_graph.TypedGraph(\n",
    "        context=typed_graph.Context(n_graph=np.array([1]), features=()),\n",
    "        nodes=nodes,\n",
    "        edges=edges)\n",
    "    return grid2mesh_graph\n",
    "\n",
    "  def _init_mesh_graph(self) -> typed_graph.TypedGraph:\n",
    "    \"\"\"Build Mesh graph.\"\"\"\n",
    "    merged_mesh = icosahedral_mesh.merge_meshes(self._meshes)\n",
    "\n",
    "    # Work simply on the mesh edges.\n",
    "    senders, receivers = icosahedral_mesh.faces_to_edges(merged_mesh.faces)\n",
    "\n",
    "    # Precompute structural node and edge features according to config options.\n",
    "    # Structural features are those that depend on the fixed values of the\n",
    "    # latitude and longitudes of the nodes.\n",
    "    assert self._mesh_nodes_lat is not None and self._mesh_nodes_lon is not None\n",
    "    node_features, edge_features = model_utils.get_graph_spatial_features(\n",
    "        node_lat=self._mesh_nodes_lat,\n",
    "        node_lon=self._mesh_nodes_lon,\n",
    "        senders=senders,\n",
    "        receivers=receivers,\n",
    "        **self._spatial_features_kwargs,\n",
    "    )\n",
    "\n",
    "    n_mesh_node = np.array([self._num_mesh_nodes])\n",
    "    n_edge = np.array([senders.shape[0]])\n",
    "    assert n_mesh_node == len(node_features)\n",
    "    mesh_node_set = typed_graph.NodeSet(\n",
    "        n_node=n_mesh_node, features=node_features)\n",
    "    edge_set = typed_graph.EdgeSet(\n",
    "        n_edge=n_edge,\n",
    "        indices=typed_graph.EdgesIndices(senders=senders, receivers=receivers),\n",
    "        features=edge_features)\n",
    "    nodes = {\"mesh_nodes\": mesh_node_set}\n",
    "    edges = {\n",
    "        typed_graph.EdgeSetKey(\"mesh\", (\"mesh_nodes\", \"mesh_nodes\")): edge_set\n",
    "    }\n",
    "    mesh_graph = typed_graph.TypedGraph(\n",
    "        context=typed_graph.Context(n_graph=np.array([1]), features=()),\n",
    "        nodes=nodes,\n",
    "        edges=edges)\n",
    "\n",
    "    return mesh_graph\n",
    "\n",
    "  def _init_mesh2grid_graph(self) -> typed_graph.TypedGraph:\n",
    "    \"\"\"Build Mesh2Grid graph.\"\"\"\n",
    "\n",
    "    # Create some edges according to how the grid nodes are contained by\n",
    "    # mesh triangles.\n",
    "    (grid_indices,\n",
    "     mesh_indices) = grid_mesh_connectivity.in_mesh_triangle_indices(\n",
    "         grid_latitude=self._grid_lat,\n",
    "         grid_longitude=self._grid_lon,\n",
    "         mesh=self._finest_mesh)\n",
    "\n",
    "    # Edges sending info from mesh to grid.\n",
    "    senders = mesh_indices\n",
    "    receivers = grid_indices\n",
    "\n",
    "    # Precompute structural node and edge features according to config options.\n",
    "    assert self._mesh_nodes_lat is not None and self._mesh_nodes_lon is not None\n",
    "    (senders_node_features, receivers_node_features,\n",
    "     edge_features) = model_utils.get_bipartite_graph_spatial_features(\n",
    "         senders_node_lat=self._mesh_nodes_lat,\n",
    "         senders_node_lon=self._mesh_nodes_lon,\n",
    "         receivers_node_lat=self._grid_nodes_lat,\n",
    "         receivers_node_lon=self._grid_nodes_lon,\n",
    "         senders=senders,\n",
    "         receivers=receivers,\n",
    "         edge_normalization_factor=self._mesh2grid_edge_normalization_factor,\n",
    "         **self._spatial_features_kwargs,\n",
    "     )\n",
    "\n",
    "    n_grid_node = np.array([self._num_grid_nodes])\n",
    "    n_mesh_node = np.array([self._num_mesh_nodes])\n",
    "    n_edge = np.array([senders.shape[0]])\n",
    "    grid_node_set = typed_graph.NodeSet(\n",
    "        n_node=n_grid_node, features=receivers_node_features)\n",
    "    mesh_node_set = typed_graph.NodeSet(\n",
    "        n_node=n_mesh_node, features=senders_node_features)\n",
    "    edge_set = typed_graph.EdgeSet(\n",
    "        n_edge=n_edge,\n",
    "        indices=typed_graph.EdgesIndices(senders=senders, receivers=receivers),\n",
    "        features=edge_features)\n",
    "    nodes = {\"grid_nodes\": grid_node_set, \"mesh_nodes\": mesh_node_set}\n",
    "    edges = {\n",
    "        typed_graph.EdgeSetKey(\"mesh2grid\", (\"mesh_nodes\", \"grid_nodes\")):\n",
    "            edge_set\n",
    "    }\n",
    "    mesh2grid_graph = typed_graph.TypedGraph(\n",
    "        context=typed_graph.Context(n_graph=np.array([1]), features=()),\n",
    "        nodes=nodes,\n",
    "        edges=edges)\n",
    "    return mesh2grid_graph\n",
    "\n",
    "  def _run_grid2mesh_gnn(self, grid_node_features: chex.Array,\n",
    "                         ) -> tuple[chex.Array, chex.Array]:\n",
    "    \"\"\"Runs the grid2mesh_gnn, extracting latent mesh and grid nodes.\"\"\"\n",
    "\n",
    "    # Concatenate node structural features with input features.\n",
    "    batch_size = grid_node_features.shape[1]\n",
    "\n",
    "    grid2mesh_graph = self._grid2mesh_graph_structure\n",
    "    assert grid2mesh_graph is not None\n",
    "    grid_nodes = grid2mesh_graph.nodes[\"grid_nodes\"]\n",
    "    mesh_nodes = grid2mesh_graph.nodes[\"mesh_nodes\"]\n",
    "    \n",
    "    # Monte: Getting this error TypeError: concatenate requires ndarray or scalar arguments, \n",
    "    # got <class 'wofscast.xarray_jax.JaxArrayWrapper'> at position 0. Using the .jax_array, \n",
    "    # I get a TracerArrayConversionError\n",
    "    \n",
    "    grid_node_features = grid_node_features.jax_array\n",
    "    \n",
    "    # Monte: replace jnp.concatenate with xarray.concat; NOPE\n",
    "    new_grid_nodes = grid_nodes._replace(\n",
    "        features=jnp.concatenate([\n",
    "            grid_node_features,\n",
    "            _add_batch_second_axis(\n",
    "                grid_nodes.features.astype(grid_node_features.dtype),\n",
    "                batch_size)\n",
    "        ],\n",
    "                                 axis=-1))\n",
    "\n",
    "    grid_features=jnp.concatenate([\n",
    "            grid_node_features,\n",
    "            _add_batch_second_axis(\n",
    "                grid_nodes.features.astype(grid_node_features.dtype),\n",
    "                batch_size)\n",
    "        ],\n",
    "                                 axis=-1)\n",
    "    \n",
    "    print(f'\\n{grid_features.shape=}\\n')\n",
    "    \n",
    "    # To make sure capacity of the embedded is identical for the grid nodes and\n",
    "    # the mesh nodes, we also append some dummy zero input features for the\n",
    "    # mesh nodes.\n",
    "    dummy_mesh_node_features = jnp.zeros(\n",
    "        (self._num_mesh_nodes,) + grid_node_features.shape[1:],\n",
    "        dtype=grid_node_features.dtype)\n",
    "    \n",
    "\n",
    "    mesh_concat = jnp.concatenate([\n",
    "            dummy_mesh_node_features,\n",
    "            _add_batch_second_axis(\n",
    "                mesh_nodes.features.astype(dummy_mesh_node_features.dtype),\n",
    "                batch_size)\n",
    "        ],\n",
    "                                 axis=-1)\n",
    "    \n",
    "    print('\\nShape of the Mesh features')\n",
    "    print(f'{dummy_mesh_node_features.shape=}, {mesh_concat.shape=}\\n')\n",
    "    \n",
    "    new_mesh_nodes = mesh_nodes._replace(\n",
    "        features=jnp.concatenate([\n",
    "            dummy_mesh_node_features,\n",
    "            _add_batch_second_axis(\n",
    "                mesh_nodes.features.astype(dummy_mesh_node_features.dtype),\n",
    "                batch_size)\n",
    "        ],\n",
    "                                 axis=-1))\n",
    "\n",
    "\n",
    "    # Broadcast edge structural features to the required batch size.\n",
    "    grid2mesh_edges_key = grid2mesh_graph.edge_key_by_name(\"grid2mesh\")\n",
    "    edges = grid2mesh_graph.edges[grid2mesh_edges_key]\n",
    "\n",
    "\n",
    "    features=_add_batch_second_axis(\n",
    "            edges.features.astype(dummy_mesh_node_features.dtype), batch_size)\n",
    "    \n",
    "    print('\\nInside run grid2mesh:')\n",
    "    print(f\"{edges.features.shape=}, {features.shape=}\")\n",
    "    \n",
    "    new_edges = edges._replace(\n",
    "        features=_add_batch_second_axis(\n",
    "            edges.features.astype(dummy_mesh_node_features.dtype), batch_size))\n",
    "\n",
    "    \n",
    "    \n",
    "    input_graph = self._grid2mesh_graph_structure._replace(\n",
    "        edges={grid2mesh_edges_key: new_edges},\n",
    "        nodes={\n",
    "            \"grid_nodes\": new_grid_nodes,\n",
    "            \"mesh_nodes\": new_mesh_nodes\n",
    "        })\n",
    "\n",
    "    # Run the GNN.\n",
    "    print(f\"{self._grid2mesh_gnn=}\")\n",
    "    grid2mesh_out = self._grid2mesh_gnn(input_graph)\n",
    "    latent_mesh_nodes = grid2mesh_out.nodes[\"mesh_nodes\"].features\n",
    "    latent_grid_nodes = grid2mesh_out.nodes[\"grid_nodes\"].features\n",
    "    return latent_mesh_nodes, latent_grid_nodes\n",
    "\n",
    "  def _run_mesh_gnn(self, latent_mesh_nodes: chex.Array) -> chex.Array:\n",
    "    \"\"\"Runs the mesh_gnn, extracting updated latent mesh nodes.\"\"\"\n",
    "\n",
    "    # Add the structural edge features of this graph. Note we don't need\n",
    "    # to add the structural node features, because these are already part of\n",
    "    # the latent state, via the original Grid2Mesh gnn, however, we need\n",
    "    # the edge ones, because it is the first time we are seeing this particular\n",
    "    # set of edges.\n",
    "    batch_size = latent_mesh_nodes.shape[1]\n",
    "    print(f\"{latent_mesh_nodes.shape}\")\n",
    "\n",
    "    mesh_graph = self._mesh_graph_structure\n",
    "    assert mesh_graph is not None\n",
    "    mesh_edges_key = mesh_graph.edge_key_by_name(\"mesh\")\n",
    "    edges = mesh_graph.edges[mesh_edges_key]\n",
    "\n",
    "    # We are assuming here that the mesh gnn uses a single set of edge keys\n",
    "    # named \"mesh\" for the edges and that it uses a single set of nodes named\n",
    "    # \"mesh_nodes\"\n",
    "    msg = (\"The setup currently requires to only have one kind of edge in the\"\n",
    "           \" mesh GNN.\")\n",
    "    assert len(mesh_graph.edges) == 1, msg\n",
    "\n",
    "    new_edges = edges._replace(\n",
    "        features=_add_batch_second_axis(\n",
    "            edges.features.astype(latent_mesh_nodes.dtype), batch_size))\n",
    "\n",
    "    nodes = mesh_graph.nodes[\"mesh_nodes\"]\n",
    "    nodes = nodes._replace(features=latent_mesh_nodes)\n",
    "\n",
    "    input_graph = mesh_graph._replace(\n",
    "        edges={mesh_edges_key: new_edges}, nodes={\"mesh_nodes\": nodes})\n",
    "\n",
    "    # Run the GNN.\n",
    "    return self._mesh_gnn(input_graph).nodes[\"mesh_nodes\"].features\n",
    "\n",
    "  def _run_mesh2grid_gnn(self,\n",
    "                         updated_latent_mesh_nodes: chex.Array,\n",
    "                         latent_grid_nodes: chex.Array,\n",
    "                         ) -> chex.Array:\n",
    "    \"\"\"Runs the mesh2grid_gnn, extracting the output grid nodes.\"\"\"\n",
    "\n",
    "    # Add the structural edge features of this graph. Note we don't need\n",
    "    # to add the structural node features, because these are already part of\n",
    "    # the latent state, via the original Grid2Mesh gnn, however, we need\n",
    "    # the edge ones, because it is the first time we are seeing this particular\n",
    "    # set of edges.\n",
    "    batch_size = updated_latent_mesh_nodes.shape[1]\n",
    "    \n",
    "    print('in run_mesh2grid....')\n",
    "    print(f\"{updated_latent_mesh_nodes.shape=}, {latent_grid_nodes.shape=}\")\n",
    "    \n",
    "\n",
    "    mesh2grid_graph = self._mesh2grid_graph_structure\n",
    "    assert mesh2grid_graph is not None\n",
    "    mesh_nodes = mesh2grid_graph.nodes[\"mesh_nodes\"]\n",
    "    grid_nodes = mesh2grid_graph.nodes[\"grid_nodes\"]\n",
    "    new_mesh_nodes = mesh_nodes._replace(features=updated_latent_mesh_nodes)\n",
    "    new_grid_nodes = grid_nodes._replace(features=latent_grid_nodes)\n",
    "    mesh2grid_key = mesh2grid_graph.edge_key_by_name(\"mesh2grid\")\n",
    "    edges = mesh2grid_graph.edges[mesh2grid_key]\n",
    "\n",
    "    new_edges = edges._replace(\n",
    "        features=_add_batch_second_axis(\n",
    "            edges.features.astype(latent_grid_nodes.dtype), batch_size))\n",
    "\n",
    "    ##print(f\"{new_mesh_nodes.shape=}, {new_grid_nodes.shape=}\")\n",
    "    \n",
    "    input_graph = mesh2grid_graph._replace(\n",
    "        edges={mesh2grid_key: new_edges},\n",
    "        nodes={\n",
    "            \"mesh_nodes\": new_mesh_nodes,\n",
    "            \"grid_nodes\": new_grid_nodes\n",
    "        })\n",
    "\n",
    "    # Run the GNN.\n",
    "    output_graph = self._mesh2grid_gnn(input_graph)\n",
    "    output_grid_nodes = output_graph.nodes[\"grid_nodes\"].features\n",
    "\n",
    "    return output_grid_nodes\n",
    "\n",
    "  def _inputs_to_grid_node_features(\n",
    "      self,\n",
    "      inputs: xarray.Dataset,\n",
    "      forcings: xarray.Dataset,\n",
    "      ) -> chex.Array:\n",
    "    \"\"\"xarrays -> [num_grid_nodes, batch, num_channels].\"\"\"\n",
    "\n",
    "    # xarray `Dataset` (batch, time, lat, lon, level, multiple vars)\n",
    "    # to xarray `DataArray` (batch, lat, lon, channels)\n",
    "    \n",
    "    stacked_inputs = model_utils.dataset_to_stacked(inputs)   \n",
    "    stacked_forcings = model_utils.dataset_to_stacked(forcings)\n",
    "    \n",
    "    stacked_inputs = xarray.concat(\n",
    "        [stacked_inputs, stacked_forcings], dim=\"channels\")\n",
    "\n",
    "    # xarray `DataArray` (batch, lat, lon, channels)\n",
    "    # to single numpy array with shape [lat_lon_node, batch, channels]\n",
    "    grid_xarray_lat_lon_leading = model_utils.lat_lon_to_leading_axes(\n",
    "        stacked_inputs)\n",
    "\n",
    "    result = grid_xarray_lat_lon_leading.data.reshape(\n",
    "        (-1,) + grid_xarray_lat_lon_leading.data.shape[2:])\n",
    "    \n",
    "    #print(result, result.shape)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "  def _grid_node_outputs_to_prediction(\n",
    "      self,\n",
    "      grid_node_outputs: chex.Array,\n",
    "      targets_template: xarray.Dataset,\n",
    "      ) -> xarray.Dataset:\n",
    "    \"\"\"[num_grid_nodes, batch, num_outputs] -> xarray.\"\"\"\n",
    "    \n",
    "    # numpy array with shape [lat_lon_node, batch, channels]\n",
    "    # to xarray `DataArray` (batch, lat, lon, channels)\n",
    "    assert self._grid_lat is not None and self._grid_lon is not None\n",
    "    grid_shape = (self._grid_lat.shape[0], self._grid_lon.shape[0])\n",
    "\n",
    "    grid_outputs_lat_lon_leading = grid_node_outputs.reshape(\n",
    "        grid_shape + grid_node_outputs.shape[1:])\n",
    "    dims = (\"lat\", \"lon\", \"batch\", \"channels\")\n",
    "    \n",
    "    #grid_xarray_lat_lon_leading = xarray.DataArray(\n",
    "    #    data=grid_outputs_lat_lon_leading,\n",
    "    #    dims=dims)\n",
    "    \n",
    "    # Monte: Possibly Deprecated with newest version of jax\n",
    "    grid_xarray_lat_lon_leading = xarray_jax.DataArray(\n",
    "        data=grid_outputs_lat_lon_leading,\n",
    "        dims=dims)\n",
    "    grid_xarray = model_utils.restore_leading_axes(grid_xarray_lat_lon_leading)\n",
    "\n",
    "    # xarray `DataArray` (batch, lat, lon, channels)\n",
    "    # to xarray `Dataset` (batch, one time step, lat, lon, level, multiple vars)\n",
    "\n",
    "    return model_utils.stacked_to_dataset(\n",
    "        grid_xarray.variable, targets_template)\n",
    "\n",
    "\n",
    "def _add_batch_second_axis(data, batch_size):\n",
    "  # data [leading_dim, trailing_dim]\n",
    "  assert data.ndim == 2\n",
    "  ones = jnp.ones([batch_size, 1], dtype=data.dtype)\n",
    "  return data[:, None] * ones  # [leading_dim, batch, trailing_dim]\n",
    "\n",
    "\n",
    "def _get_max_edge_distance(mesh):\n",
    "  senders, receivers = icosahedral_mesh.faces_to_edges(mesh.faces)\n",
    "  edge_distances = np.linalg.norm(\n",
    "      mesh.vertices[senders] - mesh.vertices[receivers], axis=-1)\n",
    "  return edge_distances.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4244d737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
