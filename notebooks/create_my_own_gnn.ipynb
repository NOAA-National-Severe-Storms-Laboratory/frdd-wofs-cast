{
 "cells": [
  {
   "cell_type": "raw",
   "id": "05a86f9c",
   "metadata": {},
   "source": [
    "The model works with 3 graphs:\n",
    "  * Grid2Mesh graph: Graph that contains all nodes. This graph is strictly\n",
    "    bipartite with edges going from grid nodes (NWP grid) to mesh nodes using a\n",
    "    fixed radius query. The grid2mesh_gnn will operate in this graph. The output\n",
    "    of this stage will be a latent representation for the mesh nodes, and a\n",
    "    latent representation for the grid nodes.\n",
    "    \n",
    "  * Mesh graph: Graph that contains mesh nodes only. The mesh_gnn will\n",
    "    operate in this graph. It will update the latent state of the mesh nodes\n",
    "    only.\n",
    "    \n",
    "  * Mesh2Grid graph: Graph that contains all nodes. This graph is strictly\n",
    "    bipartite with edges going from mesh nodes to grid nodes such that each grid\n",
    "    nodes is connected to 3 nodes of the mesh triangular face that contains\n",
    "    the grid points. The mesh2grid_gnn will operate in this graph. It will\n",
    "    process the updated latent state of the mesh nodes, and the latent state\n",
    "    of the grid nodes, to produce the final output for the grid nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5068f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_gnn as tfgnn\n",
    "import sys, os \n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "from wofscast import model_utils\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ee04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = xr.load_dataset('/work/mflora/wofs-cast-data/dataset_20200505.nc')\n",
    "# subsample by level\n",
    "ds = ds.drop_vars('datetime')\n",
    "levels = [0,1,10]\n",
    "ds = ds.isel(level=(levels))\n",
    "ds = ds.expand_dims(dim='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ba3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_dataset(dataset: xr.Dataset) -> np.ndarray:\n",
    "    \"\"\"Stack a dataset from (batch, time, lat, lon, level, multiple vars)\n",
    "       -> [num_grid_points, batch, n_channels]\n",
    "       \n",
    "    Args:\n",
    "        dataset (xarray.Dataset): The input dataset with dimensions (batch, time, lat, lon, level, ...).\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: A NumPy array with shape [num_grid_points, batch, n_channels].\n",
    "    \"\"\"\n",
    "    # Stack spatial dimensions into a single 'nodes' dimension\n",
    "    ds_stacked = dataset.stack(nodes=('lat', 'lon'))\n",
    "    \n",
    "    # Combine all other dimensions (except 'batch') into a single 'channels' dimension\n",
    "    # This includes 'time', 'level', and potentially multiple variables if the dataset has more than one data variable\n",
    "    non_batch_dims = [dim for dim in ds_stacked.dims if dim != 'batch' and dim != 'nodes']\n",
    "    ds_combined = ds_stacked.to_array(dim='variable').stack(channels=(non_batch_dims + ['variable']))\n",
    "    \n",
    "    # Transpose to order dimensions as [nodes, batch, channels]\n",
    "    ds_ordered = ds_combined.transpose('nodes', 'batch', 'channels')\n",
    "    \n",
    "    # Convert to NumPy array\n",
    "    result_array = ds_ordered.values\n",
    "    \n",
    "    # The result_array shape will be [num_grid_points, batch, n_channels]\n",
    "    # where 'n_channels' includes all combinations of 'time', 'level', and variables\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22477320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid: NWP grid points/nodes\n",
    "# mesh: GNN Mesh nodes \n",
    "\n",
    "# latent size: n_channels -> latent size\n",
    "# hidden_layers : the hidden layers in NN used for \n",
    "#                 the message-passing in the GNN\n",
    "\n",
    "class MeshGNN:\n",
    "    def __init__(self, latent_size = 32, hidden_layers = 1):\n",
    "        # Encoder, which moves data from the grid to the mesh with a single message\n",
    "    # passing step.\n",
    "    self._grid2mesh_gnn = deep_typed_graph_net.DeepTypedGraphNet(\n",
    "        embed_nodes=True,  # Embed raw features of the grid and mesh nodes.\n",
    "        embed_edges=True,  # Embed raw features of the grid2mesh edges.\n",
    "        edge_latent_size=dict(grid2mesh=latent_size),\n",
    "        node_latent_size=dict(\n",
    "            mesh_nodes=latent_size,\n",
    "            grid_nodes=latent_size),\n",
    "        mlp_hidden_size=latent_size,\n",
    "        mlp_num_hidden_layers=hidden_layers,\n",
    "        num_message_passing_steps=1,\n",
    "        use_layer_norm=True,\n",
    "        include_sent_messages_in_node_update=False,\n",
    "        activation=\"swish\",\n",
    "        f32_aggregation=True,\n",
    "        aggregate_normalization=None,\n",
    "        name=\"grid2mesh_gnn\",\n",
    "    )\n",
    "    \n",
    "    def __call__(self, inputs, targets):\n",
    "        # Convert all input data into flat vectors for each of the grid nodes.\n",
    "        # xarray.Dataset(batch, time, lat, lon, level, multiple vars, forcings)\n",
    "        # -> [num_grid_points, batch, num_channels]\n",
    "        grid_node_features = self._inputs_to_grid_node_features(X)\n",
    "    \n",
    "        # Transfer data for the grid to the mesh,\n",
    "        # [num_mesh_nodes, batch, latent_size], [num_grid_nodes, batch, latent_size]\n",
    "        (latent_mesh_nodes, latent_grid_nodes\n",
    "         ) = self._run_grid2mesh_gnn(grid_node_features\n",
    "    \n",
    "    def _inputs_to_grid_node_features(self, inputs: xarray.Dataset) -> np.ndarray:\n",
    "        \"\"\"xarray Dataset -> nu,py [num_grid_nodes, batch, num_channels]\"\"\"\n",
    "        return stack_dataset(inputs)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
