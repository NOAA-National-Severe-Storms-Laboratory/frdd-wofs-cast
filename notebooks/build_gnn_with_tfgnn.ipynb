{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8e7c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 17:45:00.814238: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-20 17:45:00.839897: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-20 17:45:00.839925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-20 17:45:00.840691: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-20 17:45:00.845147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 17:45:01.879859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running TF-GNN 1.0.2 with TensorFlow 2.15.0.\n"
     ]
    }
   ],
   "source": [
    "import sys, os \n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_gnn as tfgnn\n",
    "\n",
    "print(f'Running TF-GNN {tfgnn.__version__} with TensorFlow {tf.__version__}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c91805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wofscast import deep_typed_graph_net\n",
    "from wofscast import grid_mesh_connectivity\n",
    "from wofscast import icosahedral_mesh, square_mesh\n",
    "from wofscast.encode_process_decode import EncodeProcessDecode\n",
    "from wofscast import losses\n",
    "from wofscast import model_utils, data_utils\n",
    "from wofscast import my_graphcast as graphcast\n",
    "#from . import predictor_base\n",
    "#from . import typed_graph\n",
    "from glob import glob\n",
    "import xarray\n",
    "import dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab94cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables = ['U', 'V', 'W',]# 'T', 'P', 'REFL_10CM', 'UP_HELI_MAX']\n",
    "target_variables = ['U', 'V', 'W',]# 'T', 'P', 'REFL_10CM', 'UP_HELI_MAX']\n",
    "forcing_variables = [\"XLAND\"]\n",
    "\n",
    "vars_2D = [] #['UP_HELI_MAX']\n",
    "\n",
    "n_vars_2D = len(vars_2D)\n",
    "n_vars_3D = len(input_variables) - n_vars_2D\n",
    "\n",
    "# Weights used in the loss equation.\n",
    "VARIABLE_WEIGHTS = {v : 1.0 for v in target_variables}\n",
    "#VARIABLE_WEIGHTS['REFL_10CM'] = 2.0\n",
    "#VARIABLE_WEIGHTS['UP_HELI_MAX'] = 2.0\n",
    "\n",
    "\n",
    "# Not pressure levels, but just vertical array indices at the moment. \n",
    "pressure_levels = list(np.arange(0,30,4))\n",
    "radius_query_fraction_edge_length=0.6\n",
    "hidden_layers = 1\n",
    "\n",
    "# Loads data from the past 10 minutes and \n",
    "# creates a target lead time 5-30, in 5 min intervals\n",
    "input_duration = '10min'\n",
    "train_lead_times = '5min' \n",
    "eval_lead_times = slice('10min', '25min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e59967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_config = graphcast.TaskConfig(\n",
    "      input_variables=input_variables,\n",
    "      target_variables=target_variables,\n",
    "      forcing_variables=forcing_variables,\n",
    "      pressure_levels=pressure_levels,\n",
    "      input_duration=input_duration,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3723b20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Examples:   {'batch': 1, 'time': 6, 'level': 50, 'lat': 300, 'lon': 300, 'datetime': 6}\n",
      "********************************************************************************\n",
      "Train Inputs:   {'batch': 32, 'time': 2, 'level': 8, 'lat': 300, 'lon': 300}\n",
      "Train Targets:  {'batch': 32, 'time': 1, 'level': 8, 'lat': 300, 'lon': 300}\n",
      "Train Forcings: {'batch': 32, 'time': 1, 'lat': 300, 'lon': 300}\n",
      "********************************************************************************\n",
      "Eval Inputs:    {'batch': 1, 'time': 1, 'level': 8, 'lat': 300, 'lon': 300}\n",
      "Eval Targets:   {'batch': 1, 'time': 4, 'level': 8, 'lat': 300, 'lon': 300}\n",
      "Eval Forcings:  {'batch': 1, 'time': 4, 'lat': 300, 'lon': 300}\n"
     ]
    }
   ],
   "source": [
    "# Load the data \n",
    "data_paths = glob(os.path.join('/work/mflora/wofs-cast-data/dataset*.nc'))\n",
    "data_paths.sort()\n",
    "\n",
    "data_paths = [data_paths[0]]*32\n",
    "\n",
    "train_input_list = []\n",
    "train_target_list = []\n",
    "train_forcing_list = []\n",
    "\n",
    "dataset = xarray.load_dataset(data_paths[0])\n",
    "\n",
    "for path in data_paths:\n",
    "\n",
    "    # @title Extract training and eval data\n",
    "    example_batch = dataset.expand_dims(dim='batch', axis=0)\n",
    "\n",
    "    _train_inputs, _train_targets, _train_forcings = data_utils.extract_inputs_targets_forcings(\n",
    "        example_batch, target_lead_times=train_lead_times,\n",
    "        **dataclasses.asdict(task_config))\n",
    "\n",
    "    train_input_list.append(_train_inputs)\n",
    "    train_target_list.append(_train_targets)\n",
    "    train_forcing_list.append(_train_forcings)\n",
    "    \n",
    "# just load some data from the last dataset for evaluation. \n",
    "eval_inputs, eval_targets, eval_forcings = data_utils.extract_inputs_targets_forcings(\n",
    "        example_batch, target_lead_times=eval_lead_times,\n",
    "        **dataclasses.asdict(task_config))\n",
    "\n",
    "train_inputs = xarray.concat(train_input_list, dim='batch')\n",
    "train_targets = xarray.concat(train_target_list, dim='batch')\n",
    "train_forcings = xarray.concat(train_forcing_list, dim='batch')\n",
    "    \n",
    "print(\"All Examples:  \", example_batch.dims.mapping)\n",
    "print(\"*\"*80)\n",
    "print(\"Train Inputs:  \", train_inputs.dims.mapping)\n",
    "print(\"Train Targets: \", train_targets.dims.mapping)\n",
    "print(\"Train Forcings:\", train_forcings.dims.mapping)\n",
    "print(\"*\"*80)\n",
    "print(\"Eval Inputs:   \", eval_inputs.dims.mapping)\n",
    "print(\"Eval Targets:  \", eval_targets.dims.mapping)\n",
    "print(\"Eval Forcings: \", eval_forcings.dims.mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "271f05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_dataset(dataset: xarray.Dataset) -> np.ndarray:\n",
    "    \"\"\"Stack a dataset from (batch, time, lat, lon, level, multiple vars)\n",
    "       -> [n_examples, num_grid_points, n_channels]\n",
    "       \n",
    "    Args:\n",
    "        dataset (xarray.Dataset): The input dataset with dimensions (batch, time, lat, lon, level, ...).\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: A NumPy array with shape [num_grid_points, batch_size, n_channels].\n",
    "    \"\"\"\n",
    "    # Stack spatial dimensions into a single 'nodes' dimension\n",
    "    ds_stacked = dataset.stack(nodes=('lat', 'lon'))\n",
    "    \n",
    "    # Combine all other dimensions (except 'batch') into a single 'channels' dimension\n",
    "    # This includes 'time', 'level', and potentially multiple variables if the dataset has more than one data variable\n",
    "    non_batch_dims = [dim for dim in ds_stacked.dims if dim != 'batch' and dim != 'nodes']\n",
    "    ds_combined = ds_stacked.to_array(dim='variable').stack(channels=(non_batch_dims + ['variable']))\n",
    "    \n",
    "    # Transpose to order dimensions as [nodes, batch, channels]\n",
    "    ds_ordered = ds_combined.transpose('nodes', 'batch', 'channels')\n",
    "    \n",
    "    # Convert to NumPy array\n",
    "    result_array = ds_ordered.values\n",
    "    \n",
    "    # The result_array shape will be [num_grid_points, batch, n_channels]\n",
    "    # where 'n_channels' includes all combinations of 'time', 'level', and variables\n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4adf490b",
   "metadata": {},
   "source": [
    "if False: #self.build_grid2mesh_tensor:\n",
    "            n_channels = grid_node_features.shape[-1] + senders_node_features.shape[-1]\n",
    "            \n",
    "            # Build the GraphTensorSpec Object instead \n",
    "            graph_tensor_spec = tfgnn.GraphTensorSpec.from_piece_specs(\n",
    "                    context_spec=tfgnn.ContextSpec.from_field_specs(features_spec = {}, \n",
    "                                                  sizes_spec= tf.TensorSpec(shape=(1,), dtype=tf.int32)\n",
    "                                                                   ),\n",
    "                node_sets_spec={\n",
    "            'grid_nodes':\n",
    "                tfgnn.NodeSetSpec.from_field_specs(\n",
    "                features_spec={\n",
    "                    tfgnn.HIDDEN_STATE:\n",
    "                        tf.TensorSpec((n_grid_node[0], None, n_channels), tf.float32)\n",
    "                },\n",
    "                sizes_spec=tf.TensorSpec(n_grid_node, tf.int32)),\n",
    "             \n",
    "             'mesh_nodes':\n",
    "                tfgnn.NodeSetSpec.from_field_specs(\n",
    "                features_spec={\n",
    "                    tfgnn.HIDDEN_STATE:\n",
    "                        tf.TensorSpec((n_mesh_node[0], None, n_channels), tf.float32)\n",
    "                },\n",
    "                sizes_spec=tf.TensorSpec(n_mesh_node, tf.int32))\n",
    "                    \n",
    "            },\n",
    "            edge_sets_spec={\n",
    "                \"grid2mesh_edges\":\n",
    "                tfgnn.EdgeSetSpec.from_field_specs(\n",
    "                features_spec={\n",
    "                    tfgnn.HIDDEN_STATE:\n",
    "                        tf.TensorSpec((edge_features.shape[0], None, edge_features.shape[1]), tf.float32)\n",
    "                },\n",
    "                sizes_spec=tf.TensorSpec(n_edge, tf.int32),\n",
    "                adjacency_spec=tfgnn.AdjacencySpec.from_incident_node_sets(\n",
    "                    'grid_nodes', 'mesh_nodes'))\n",
    "            })\n",
    "        \n",
    "            self.build_grid2mesh_tensor = False\n",
    "            \n",
    "            # For the error!\n",
    "            graph_tensor_spec.spec = graph_tensor_spec\n",
    "            \n",
    "            return graph_tensor_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8ee13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_max_edge_distance(mesh):\n",
    "    senders, receivers = icosahedral_mesh.faces_to_edges(mesh.faces)\n",
    "    edge_distances = np.linalg.norm(\n",
    "      mesh.vertices[senders] - mesh.vertices[receivers], axis=-1)\n",
    "    \n",
    "    return edge_distances.max()\n",
    "\n",
    "class GNNDataPreprocessor:\n",
    "    def __init__(self, inputs, \n",
    "                 n_levels, \n",
    "                 n_vars_3D, \n",
    "                 n_vars_2D,\n",
    "                 n_meshes=2, \n",
    "                 grid2mesh_radius=0.1, \n",
    "                 mesh2grid_edge_normalization_factor=None):\n",
    "        \n",
    "        # For the spatial feature creation for the Grid2Mesh and Mesh2Grid Graphs\n",
    "        self._spatial_features_kwargs = dict(\n",
    "            add_node_positions=False,\n",
    "            add_node_latitude=True,\n",
    "            add_node_longitude=True,\n",
    "            add_relative_positions=True,\n",
    "            relative_longitude_local_coordinates=True,\n",
    "            relative_latitude_local_coordinates=True,\n",
    "        )\n",
    "\n",
    "        # Init the multi-mesh structure\n",
    "        self._init_mesh(n_meshes)\n",
    "        \n",
    "        self.num_outputs = self.determine_num_outputs(n_levels, n_vars_3D, n_vars_2D)\n",
    "        \n",
    "        # Obtain the query radius in absolute units for the unit-sphere for the\n",
    "        # grid2mesh model, by rescaling the `radius_query_fraction_edge_length`.\n",
    "        self._query_radius = (_get_max_edge_distance(self._finest_mesh)\n",
    "                          * grid2mesh_radius)\n",
    "        \n",
    "        self._mesh2grid_edge_normalization_factor = (\n",
    "            mesh2grid_edge_normalization_factor\n",
    "        )\n",
    "        \n",
    "        self._init_mesh_properties()\n",
    "        \n",
    "        self._init_grid_properties(\n",
    "              grid_lat=inputs.lat, grid_lon=inputs.lon)\n",
    "        \n",
    "        #self.compute_grid2mesh_features()\n",
    "        \n",
    "        #self.build_grid2mesh_tensor= True\n",
    "        \n",
    "        \n",
    "    def determine_num_outputs(self, n_levels, n_vars_3D, n_vars_2D):\n",
    "        num_outputs = n_vars_2D + (n_levels * n_vars_3D)\n",
    "        \n",
    "        return num_outputs\n",
    "    \n",
    "    def _init_mesh(self, n_meshes):\n",
    "        # Specification of the multimesh.\n",
    "        self._meshes = (\n",
    "        icosahedral_mesh.get_hierarchy_of_triangular_meshes_for_sphere(\n",
    "            splits=n_meshes))\n",
    "    \n",
    "    @property\n",
    "    def _finest_mesh(self):\n",
    "        return self._meshes[-1]\n",
    "    \n",
    "    def _init_grid_properties(self, grid_lat: np.ndarray, grid_lon: np.ndarray):\n",
    "        \"\"\"Inits static properties that have to do with grid nodes.\"\"\"\n",
    "        self._grid_lat = grid_lat.astype(np.float32)\n",
    "        self._grid_lon = grid_lon.astype(np.float32)\n",
    "        # Initialized the counters.\n",
    "        self._num_grid_nodes = grid_lat.shape[0] * grid_lon.shape[0]\n",
    "\n",
    "        # Initialize lat and lon for the grid.\n",
    "        grid_nodes_lon, grid_nodes_lat = np.meshgrid(grid_lon, grid_lat)\n",
    "        self._grid_nodes_lon = grid_nodes_lon.reshape([-1]).astype(np.float32)\n",
    "        self._grid_nodes_lat = grid_nodes_lat.reshape([-1]).astype(np.float32)\n",
    "    \n",
    "\n",
    "    def _init_mesh_properties(self):\n",
    "        \"\"\"Inits static properties that have to do with mesh nodes.\"\"\"\n",
    "        self._num_mesh_nodes = self._finest_mesh.vertices.shape[0]\n",
    "        mesh_phi, mesh_theta = model_utils.cartesian_to_spherical(\n",
    "            self._finest_mesh.vertices[:, 0],\n",
    "            self._finest_mesh.vertices[:, 1],\n",
    "            self._finest_mesh.vertices[:, 2])\n",
    "        (\n",
    "            mesh_nodes_lat,\n",
    "            mesh_nodes_lon,\n",
    "        ) = model_utils.spherical_to_lat_lon(\n",
    "            phi=mesh_phi, theta=mesh_theta)\n",
    "        # Convert to f32 to ensure the lat/lon features aren't in f64.\n",
    "        self._mesh_nodes_lat = mesh_nodes_lat.astype(np.float32)\n",
    "        self._mesh_nodes_lon = mesh_nodes_lon.astype(np.float32)\n",
    "    \n",
    "    \n",
    "    def compute_grid2mesh_features(self, grid_node_features):\n",
    "        # Create some edges according to distance between mesh and grid nodes.\n",
    "        # Create some edges according to distance between mesh and grid nodes.\n",
    "        assert self._grid_lat is not None and self._grid_lon is not None\n",
    "        (grid_indices, mesh_indices) = grid_mesh_connectivity.radius_query_indices(\n",
    "            grid_latitude=self._grid_lat,\n",
    "            grid_longitude=self._grid_lon,\n",
    "            mesh=self._finest_mesh,\n",
    "            radius=self._query_radius)\n",
    "\n",
    "        # Edges sending info from grid to mesh.\n",
    "        senders = grid_indices\n",
    "        receivers = mesh_indices\n",
    "\n",
    "        # Precompute structural node and edge features according to config options.\n",
    "        # Structural features are those that depend on the fixed values of the\n",
    "        # latitude and longitudes of the nodes.\n",
    "        (senders_node_features, receivers_node_features,\n",
    "         edge_features) = model_utils.get_bipartite_graph_spatial_features(\n",
    "             senders_node_lat=self._grid_nodes_lat,\n",
    "             senders_node_lon=self._grid_nodes_lon,\n",
    "             receivers_node_lat=self._mesh_nodes_lat,\n",
    "             receivers_node_lon=self._mesh_nodes_lon,\n",
    "             senders=senders,\n",
    "             receivers=receivers,\n",
    "             **self._spatial_features_kwargs,\n",
    "         )\n",
    "\n",
    "        batch_size = grid_node_features.shape[1]\n",
    "        \n",
    "        # Get the sender node features (from the grid)\n",
    "        data = _add_batch_second_axis(senders_node_features, batch_size)\n",
    "        senders_node_features = np.concatenate([grid_node_features, data], axis=-1) \n",
    "        \n",
    "        # Get the receiver node features (to the mesh)\n",
    "        dummy_mesh_node_features = np.zeros((self._num_mesh_nodes, batch_size, grid_node_features.shape[-1]),\n",
    "                dtype=grid_node_features.dtype)\n",
    "        \n",
    "        data = _add_batch_second_axis(receivers_node_features, batch_size)\n",
    "        receivers_node_features =tf.concat([dummy_mesh_node_features, data],axis=-1)\n",
    "        \n",
    "        # Get the edge features (grid2mesh edges)\n",
    "        edge_features =  _add_batch_second_axis(edge_features, batch_size)\n",
    "        \n",
    "        self.grid2mesh_features = {'grid_nodes': {'senders_node_features' : senders_node_features}, \n",
    "                            'mesh_nodes': {'receivers_node_features': receivers_node_features}, \n",
    "                            'edge_features' : edge_features, \n",
    "                            'senders' : senders, \n",
    "                            'receivers': receivers,\n",
    "                           }\n",
    "        \n",
    "    def _init_grid2mesh_tensor(self, grid_node_features) -> tfgnn.GraphTensor: \n",
    "        \"\"\"Build Grid2Mesh graph tensor for a single xample. \n",
    "        \n",
    "            grid_node_features : Flattened version of the input (n_examples, n_nodes, n_channels) \n",
    "            \n",
    "        \"\"\"\n",
    "        senders = self.grid2mesh_data['senders']\n",
    "        receivers = self.grid2mesh_data['receivers']\n",
    "        senders_node_features = self.grid2mesh_data['senders_node_features']\n",
    "        receivers_node_features = self.grid2mesh_data['receivers_node_features']\n",
    "        edge_features = self.grid2mesh_data['edge_features']\n",
    "        \n",
    "        n_grid_node = np.array([self._num_grid_nodes])\n",
    "        n_mesh_node = np.array([self._num_mesh_nodes])\n",
    "        n_edge = np.array([receivers.shape[0]])\n",
    "        n_grid_features = senders_node_features.shape[-1]\n",
    "        n_mesh_features = receivers_node_features.shape[-1]\n",
    "        \n",
    "        # Expand for a single batch size.\n",
    "        ###print(f\"{grid_node_features.shape=}, {type(grid_node_features)=}\") # (None, 90000, 48)\n",
    "        #grid_node_features = tf.transpose(grid_node_features, perm=[1,0,2])\n",
    "        #print(f\"New Shape: {grid_node_features.shape=}\")\n",
    "        \n",
    "        # Concatenate node structural features with input features.\n",
    "        #batch_size = grid_node_features.shape[1]\n",
    "        \n",
    "        # Concatenate with the sample input. \n",
    "        #data = tf.convert_to_tensor(_add_batch_second_axis(senders_node_features, batch_size, symbolic=True))\n",
    "        data = tf.convert_to_tensor(senders_node_features)\n",
    "\n",
    "        senders_node_features = tf.concat([grid_node_features, data], axis=-1)\n",
    "        # To make sure capacity of the embedded is identical for the grid nodes and\n",
    "        # the mesh nodes, we also append some dummy zero input features for the\n",
    "        # mesh nodes.\n",
    "        dummy_mesh_node_features = tf.zeros((self._num_mesh_nodes, grid_node_features.shape[-1]),\n",
    "                dtype=grid_node_features.dtype)\n",
    "        \n",
    "        receiver_data = tf.convert_to_tensor(receivers_node_features)\n",
    "        receivers_node_features =tf.concat([dummy_mesh_node_features, receiver_data],axis=-1)\n",
    "   \n",
    "        # Batch size needs to be the middle axis\n",
    "        #senders_node_features = tf.transpose(senders_node_features, perm=[1,0,2])\n",
    "        #receivers_node_features = tf.transpose(receivers_node_features, perm=[1,0,2])\n",
    "\n",
    "        # Initialize NodeSets (x,y coordindates of the senders and receivers)\n",
    "        senders_node_features_dict = {tfgnn.HIDDEN_STATE: senders_node_features}\n",
    "        receivers_node_features_dict = {tfgnn.HIDDEN_STATE: receivers_node_features}\n",
    "        \n",
    "        grid_node_set = tfgnn.NodeSet.from_fields(features=senders_node_features_dict, \n",
    "                                            sizes=n_grid_node)\n",
    "        mesh_node_set = tfgnn.NodeSet.from_fields(features=receivers_node_features_dict, \n",
    "                                            sizes=n_mesh_node)\n",
    "        \n",
    "        # Create adjacency using source and target nodes\n",
    "        adjacency = tfgnn.Adjacency.from_indices(\n",
    "            source=(\"grid_nodes\", senders),\n",
    "            target=(\"mesh_nodes\", receivers)\n",
    "        )\n",
    "\n",
    "        edge_features =  tf.convert_to_tensor(edge_features)\n",
    "        n_edge_features = edge_features.shape[-1]\n",
    "     \n",
    "        # Initialize EdgeSet\n",
    "        edge_set = tfgnn.EdgeSet.from_fields(features={tfgnn.HIDDEN_STATE: edge_features},\n",
    "                                       sizes=n_edge, \n",
    "                                       adjacency=adjacency)\n",
    "        \n",
    "        # Define the number of graph components; for a single component, this would be [1]\n",
    "        num_components = tf.constant([1], dtype=tf.int32)  # Assuming a single graph component\n",
    "\n",
    "        # Initialize Context without specific features but with the number of components\n",
    "        graph_context = tfgnn.Context.from_fields(features = {}, \n",
    "                                                  sizes=num_components)\n",
    "        \n",
    "        # Constructing the GraphTensor\n",
    "        graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "            #context = graph_context, \n",
    "            node_sets={\n",
    "                \"grid_nodes\": grid_node_set,\n",
    "                \"mesh_nodes\": mesh_node_set\n",
    "            },\n",
    "            edge_sets={\n",
    "                \"grid2mesh_edges\": edge_set\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return graph_tensor\n",
    "        \n",
    "    def _init_mesh_tensor(self, latent_mesh_nodes) -> tfgnn.GraphTensor:\n",
    "        \"\"\"Build Mesh graph tensor\"\"\"\n",
    "        # Add the structural edge features of this graph. Note we don't need\n",
    "        # to add the structural node features, because these are already part of\n",
    "        # the latent state, via the original Grid2Mesh gnn, however, we need\n",
    "        # the edge ones, because it is the first time we are seeing this particular\n",
    "        # set of edges.\n",
    "        batch_size = latent_mesh_nodes.shape[1]\n",
    "        \n",
    "        merged_mesh = icosahedral_mesh.merge_meshes(self._meshes)\n",
    "\n",
    "        # Work simply on the mesh edges.\n",
    "        senders, receivers = icosahedral_mesh.faces_to_edges(merged_mesh.faces)\n",
    "\n",
    "        # Precompute structural node and edge features according to config options.\n",
    "        # Structural features are those that depend on the fixed values of the\n",
    "        # latitude and longitudes of the nodes.\n",
    "        assert self._mesh_nodes_lat is not None and self._mesh_nodes_lon is not None\n",
    "        node_features, edge_features = model_utils.get_graph_spatial_features(\n",
    "            node_lat=self._mesh_nodes_lat,\n",
    "            node_lon=self._mesh_nodes_lon,\n",
    "            senders=senders,\n",
    "            receivers=receivers,\n",
    "            **self._spatial_features_kwargs,\n",
    "        )\n",
    "\n",
    "        n_mesh_node = np.array([self._num_mesh_nodes])\n",
    "        n_edge = np.array([senders.shape[0]])\n",
    "        assert n_mesh_node == len(node_features)\n",
    "        \n",
    "        # Initialize NodeSets (x,y coordindates of the senders and receivers\n",
    "        node_features_dict = {tfgnn.HIDDEN_STATE: latent_mesh_nodes}\n",
    "        \n",
    "        mesh_node_set = tfgnn.NodeSet.from_fields(features=node_features_dict, \n",
    "                                                  sizes=n_mesh_node)\n",
    "        \n",
    "        # Create adjacency using source and target nodes\n",
    "        adjacency = tfgnn.Adjacency.from_indices(\n",
    "            source=(\"mesh_nodes\", senders),\n",
    "            target=(\"mesh_nodes\", receivers)\n",
    "        )\n",
    "        \n",
    "        # Initialize EdgeSet\n",
    "        edge_features =  _add_batch_second_axis(edge_features, batch_size)\n",
    "        edge_set = tfgnn.EdgeSet.from_fields(features={tfgnn.HIDDEN_STATE: edge_features},\n",
    "                                       sizes=n_edge, \n",
    "                                       adjacency=adjacency)\n",
    "        \n",
    "        # Define the number of graph components; for a single component, this would be [1]\n",
    "        num_components = tf.constant([1], dtype=tf.int32)  # Assuming a single graph component\n",
    "\n",
    "        # Initialize Context without specific features but with the number of components\n",
    "        graph_context = tfgnn.Context.from_fields(sizes=num_components)\n",
    "        \n",
    "        # Constructing the GraphTensor\n",
    "        graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "            context = graph_context, \n",
    "            node_sets={\n",
    "                \"mesh_nodes\": mesh_node_set\n",
    "            },\n",
    "            edge_sets={\n",
    "                \"mesh_edges\": edge_set\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return graph_tensor\n",
    "    \n",
    "    def _init_mesh2grid_tensor(self, mesh_nodes, grid_nodes) -> tfgnn.GraphTensor:\n",
    "        \"\"\"Build Mesh2Grid graph from the updated latent mesh nodes and the \n",
    "        original latent grid nodes from the grid2mesh transformation.\"\"\"\n",
    "\n",
    "        batch_size = mesh_nodes.shape[1]\n",
    "        \n",
    "        # Create some edges according to how the grid nodes are contained by\n",
    "        # mesh triangles.\n",
    "        (grid_indices,\n",
    "         mesh_indices) = grid_mesh_connectivity.in_mesh_triangle_indices(\n",
    "             grid_latitude=self._grid_lat,\n",
    "             grid_longitude=self._grid_lon,\n",
    "             mesh=self._finest_mesh)\n",
    "\n",
    "        # Edges sending info from mesh to grid.\n",
    "        senders = mesh_indices.astype(int)#, dtype=tf.int32\n",
    "        receivers = grid_indices.astype(int)#, dtype=tf.int32\n",
    "\n",
    "        # Precompute structural node and edge features according to config options.\n",
    "        assert self._mesh_nodes_lat is not None and self._mesh_nodes_lon is not None\n",
    "        \n",
    "        (senders_node_features, receivers_node_features,\n",
    "         edge_features) = model_utils.get_bipartite_graph_spatial_features(\n",
    "             senders_node_lat=self._mesh_nodes_lat,\n",
    "             senders_node_lon=self._mesh_nodes_lon,\n",
    "             receivers_node_lat=self._grid_nodes_lat,\n",
    "             receivers_node_lon=self._grid_nodes_lon,\n",
    "             senders=senders,\n",
    "             receivers=receivers,\n",
    "             edge_normalization_factor=self._mesh2grid_edge_normalization_factor,\n",
    "             **self._spatial_features_kwargs,\n",
    "         )\n",
    "\n",
    "        n_grid_node = np.array([self._num_grid_nodes])\n",
    "        n_mesh_node = np.array([self._num_mesh_nodes])\n",
    "        n_edge = np.array([senders.shape[0]])\n",
    "\n",
    "        # Initialize NodeSets for grid and mesh nodes\n",
    "        grid_node_set = tfgnn.NodeSet.from_fields(features = {tfgnn.HIDDEN_STATE: \n",
    "                                                              grid_nodes\n",
    "                                       }, \n",
    "                                                  sizes=n_grid_node)\n",
    "        \n",
    "        mesh_node_set = tfgnn.NodeSet.from_fields(features={tfgnn.HIDDEN_STATE: \n",
    "                                                            mesh_nodes}, \n",
    "                                                  sizes=n_mesh_node)\n",
    "\n",
    "        # Create adjacency for EdgeSet using source (senders) and target (receivers) nodes\n",
    "        adjacency = tfgnn.Adjacency.from_indices(\n",
    "            source=(\"mesh_nodes\", senders),\n",
    "            target=(\"grid_nodes\", receivers)\n",
    "        )\n",
    "\n",
    "        # Initialize EdgeSet\n",
    "        edge_features =  _add_batch_second_axis(edge_features, batch_size)\n",
    "        edge_set = tfgnn.EdgeSet.from_fields(features={tfgnn.HIDDEN_STATE : edge_features},\n",
    "                                             sizes=n_edge, \n",
    "                                             adjacency=adjacency)\n",
    "\n",
    "        graph_context = tfgnn.Context.from_fields(features={}, sizes=tf.constant([1]))\n",
    "        \n",
    "        # Constructing the GraphTensor\n",
    "        graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "            context = graph_context, \n",
    "            node_sets={\n",
    "                \"grid_nodes\": grid_node_set,\n",
    "                \"mesh_nodes\": mesh_node_set\n",
    "            },\n",
    "            edge_sets={\n",
    "                \"mesh2grid_edges\": edge_set\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return graph_tensor\n",
    "    \n",
    "    \n",
    "    def _grid_node_outputs_to_prediction(\n",
    "      self,\n",
    "      grid_node_outputs,\n",
    "      targets_template: xarray.Dataset,\n",
    "      ) -> xarray.Dataset:\n",
    "        \"\"\"[num_grid_nodes, batch, num_outputs] -> xarray.\"\"\"\n",
    "    \n",
    "        # numpy array with shape [lat_lon_node, batch, channels]\n",
    "        # to xarray `DataArray` (batch, lat, lon, channels)\n",
    "        assert self._grid_lat is not None and self._grid_lon is not None\n",
    "        grid_shape = (self._grid_lat.shape[0], self._grid_lon.shape[0])\n",
    "\n",
    "        grid_outputs_lat_lon_leading = grid_node_outputs.reshape(\n",
    "            grid_shape + grid_node_outputs.shape[1:])\n",
    "        dims = (\"lat\", \"lon\", \"batch\", \"channels\")\n",
    "    \n",
    "        grid_xarray_lat_lon_leading = xarray.DataArray(\n",
    "            data=grid_outputs_lat_lon_leading,\n",
    "            dims=dims)\n",
    "    \n",
    "        # Monte: Possibly Deprecated with newest version of jax\n",
    "        grid_xarray = model_utils.restore_leading_axes(grid_xarray_lat_lon_leading)\n",
    "\n",
    "        # xarray `DataArray` (batch, lat, lon, channels)\n",
    "        # to xarray `Dataset` (batch, one time step, lat, lon, level, multiple vars)\n",
    "\n",
    "        return model_utils.stacked_to_dataset(\n",
    "            grid_xarray.variable, targets_template)\n",
    "    \n",
    "def _add_batch_second_axis(data, batch_size):\n",
    "  # data [leading_dim, trailing_dim]\n",
    "  assert data.ndim == 2\n",
    "  ones = np.ones([batch_size, 1], dtype=data.dtype)\n",
    "  return data[:, None] * ones  # [leading_dim, batch, trailing_dim]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0b4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphCast(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 preprocessor, \n",
    "                 latent_size=8, \n",
    "                 num_mlp_hidden_layers=1, \n",
    "                 mlp_hidden_size=4, \n",
    "                 num_message_passing_steps=2,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.preprocessor = preprocessor\n",
    "        self.num_mlp_hidden_layers = num_mlp_hidden_layers\n",
    "        self.latent_size = latent_size\n",
    "        self.mlp_hidden_size = mlp_hidden_size\n",
    "        self.num_message_passing_steps = num_message_passing_steps\n",
    "        \n",
    "        #TODO: determine num_outputs? \n",
    "        num_outputs = self.preprocessor.num_outputs\n",
    "        \n",
    "        self._init_grid2mesh_gnn()\n",
    "        self._init_mesh_gnn()\n",
    "        self._init_mesh2grid_gnn(num_outputs)\n",
    "    \n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "\n",
    "        # GRID2MESH ---------------------------------------------\n",
    "        input_tensor = self.preprocessor._init_grid2mesh_tensor(inputs)\n",
    "        result = self.grid2mesh_gnn(input_tensor)\n",
    "\n",
    "        latent_mesh_nodes = result.node_sets['mesh_nodes'][tfgnn.HIDDEN_STATE]\n",
    "        latent_grid_nodes = result.node_sets['grid_nodes'][tfgnn.HIDDEN_STATE]\n",
    "\n",
    "        # MESH ---------------------------------------------\n",
    "        latent_tensor = self.preprocessor._init_mesh_tensor(latent_mesh_nodes)\n",
    "        result = self.mesh_gnn(latent_tensor)\n",
    "        updated_latent_mesh_nodes = result.node_sets['mesh_nodes'][tfgnn.HIDDEN_STATE]\n",
    "\n",
    "        # MESH2GRID ---------------------------------------------\n",
    "        final_tensor = self.preprocessor._init_mesh2grid_tensor(updated_latent_mesh_nodes, \n",
    "                                                                latent_grid_nodes)\n",
    "        final_result = self.mesh2grid_gnn(final_tensor)\n",
    "        output_grid_nodes = final_result.node_sets['grid_nodes'][tfgnn.HIDDEN_STATE]\n",
    "\n",
    "        # Output Nodes to Grid \n",
    "        # Convert output flat vectors for the grid nodes to the format of the output.\n",
    "        # [num_grid_nodes, batch, output_size] ->\n",
    "        # xarray (batch, one time step, lat, lon, level, multiple vars)\n",
    "        return output_grid_nodes\n",
    "        \n",
    "    def _init_grid2mesh_gnn(self):\n",
    "        self.grid2mesh_gnn = EncodeProcessDecode(\n",
    "            encode_edges=True, # Encode raw features of the grid2mesh edges.\n",
    "            encode_nodes=True, # Encode raw features of the grid and mesh nodes.\n",
    "            edge_output_size=False,  \n",
    "            node_output_size=False,  \n",
    "            context_output_size=None,  # Don't need this output.\n",
    "            # Other configurable hyperparameters (most combinations should train).\n",
    "            num_message_passing_steps=1,\n",
    "            num_mlp_hidden_layers=self.num_mlp_hidden_layers,\n",
    "            mlp_hidden_size=self.mlp_hidden_size,\n",
    "            latent_size=self.latent_size,\n",
    "            use_layer_norm=True,\n",
    "            shared_processors=False,\n",
    "            )\n",
    "        \n",
    "    def _init_mesh_gnn(self):\n",
    "        \n",
    "        self.mesh_gnn = EncodeProcessDecode(\n",
    "            encode_edges=True,  # Encode raw features of the multi-mesh edges.\n",
    "            encode_nodes=False, # Node features already embdded by previous layers.\n",
    "            edge_output_size=False,  \n",
    "            node_output_size=False,  \n",
    "            context_output_size=None,  # Don't need this output.\n",
    "            # Other configurable hyperparameters (most combinations should train).\n",
    "            num_message_passing_steps=self.num_message_passing_steps,\n",
    "            num_mlp_hidden_layers=self.num_mlp_hidden_layers,\n",
    "            mlp_hidden_size=self.mlp_hidden_size,\n",
    "            latent_size=self.latent_size,\n",
    "            use_layer_norm=True,\n",
    "            shared_processors=False,\n",
    "            )\n",
    "     \n",
    "    def _init_mesh2grid_gnn(self, num_outputs):\n",
    "        self.mesh2grid_gnn = EncodeProcessDecode(\n",
    "            encode_edges=True,  # Encode raw features of the mesh2grid edges.\n",
    "            encode_nodes=False, # Node features already embdded by previous layers.\n",
    "            edge_output_size=None,  \n",
    "            node_output_size={'grid_nodes' : num_outputs}, \n",
    "            # Back to the number of inputs features from the grid + edges.  \n",
    "            context_output_size=None,  # Don't need this output.\n",
    "            # Other configurable hyperparameters (most combinations should train).\n",
    "            num_message_passing_steps=1,\n",
    "            num_mlp_hidden_layers=self.num_mlp_hidden_layers,\n",
    "            mlp_hidden_size=self.mlp_hidden_size,\n",
    "            latent_size=self.latent_size,\n",
    "            use_layer_norm=True,\n",
    "            shared_processors=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c95eae2d",
   "metadata": {},
   "source": [
    "self.grid2mesh_features = { 'grid_nodes': \n",
    "                              {'senders_node_features' : senders_node_features}, \n",
    "                            'mesh_nodes': \n",
    "                              {'receivers_node_features': receivers_node_features}, \n",
    "                            'edge_features' : edge_features, \n",
    "                            'senders' : senders, \n",
    "                            'receivers': receivers,\n",
    "                           }\n",
    "\n",
    "self.mesh_features = { \n",
    "                        'mesh_nodes': \n",
    "                              {'senders_node_features': receivers_node_features}, \n",
    "                        'edge_features' : edge_features, \n",
    "                        'senders' : senders, \n",
    "                        'receivers': receivers,\n",
    "                    }\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb58aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def to_graph_tensor(data, edge_set_name):\n",
    "    # Initialize Context without specific features but with the number of components\n",
    "    graph_context = tfgnn.Context.from_fields(features = {}, \n",
    "                                            sizes=tf.constant([1], dtype=tf.int32))\n",
    "    \n",
    "    node_features = [f for f in data.keys() if 'node' in f]\n",
    "    \n",
    "    need_source_and_target=False\n",
    "    if len(node_features) > 1:\n",
    "        need_source_and_target = True\n",
    "    \n",
    "    node_sets = {}\n",
    "    \n",
    "    pairs = {}\n",
    "    source=None\n",
    "    target=None\n",
    "    for node_set_name in node_features:\n",
    "        subkey = list(data[node_set_name].keys())[0]\n",
    "        size = (data[node_set_name][subkey]).shape[0] # (n_nodes, batch_size, n_channels)\n",
    "        print(f\"{node_set_name=}, {subkey=}, {size=}, {data[node_set_name][subkey].shape=}\")\n",
    "        node_sets[node_set_name] = tfgnn.NodeSet.from_fields(\n",
    "                                    features={tfgnn.HIDDEN_STATE: \n",
    "                                              data[node_set_name][subkey]}, \n",
    "                                              sizes=(size,))\n",
    "        \n",
    "       \n",
    "\n",
    "        if subkey.split('_')[0] == 'senders':\n",
    "            source = (node_set_name, data['senders']) \n",
    "        else:\n",
    "            target = (node_set_name, data['receivers']) \n",
    "           \n",
    "    #source=(\"grid_nodes\", senders),\n",
    "    #target=(\"mesh_nodes\", receivers)\n",
    "        \n",
    "    # Get adjacency matrix\n",
    "    adjacency=tfgnn.Adjacency.from_indices(source=source,target=target)\n",
    "    \n",
    "    # Constructing the GraphTensor\n",
    "    graph_tensor = tfgnn.GraphTensor.from_pieces(\n",
    "            context = graph_context, \n",
    "            node_sets=node_sets,\n",
    "            edge_sets={\n",
    "                edge_set_name: tfgnn.EdgeSet.from_fields(features={tfgnn.HIDDEN_STATE: \n",
    "                                                                   data['edge_features']},\n",
    "                                       sizes=np.array([data['senders'].shape[0]]), \n",
    "                                       adjacency=adjacency)}\n",
    "        )\n",
    "        \n",
    "    return graph_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "409cfbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_set_name='grid_nodes', subkey='senders_node_features', size=90000, data[node_set_name][subkey].shape=(90000, 32, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 17:48:42.945451: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 560.30MiB (rounded to 587520000)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-02-20 17:48:42.945493: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-02-20 17:48:42.945501: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 6, Chunks in use: 4. 1.5KiB allocated for chunks. 1.0KiB in use in bin. 32B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945505: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945509: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945512: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945515: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 2, Chunks in use: 2. 8.0KiB allocated for chunks. 8.0KiB in use in bin. 7.7KiB client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945518: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945521: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945524: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 51.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945526: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945529: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945532: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945535: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 972.0KiB allocated for chunks. 972.0KiB in use in bin. 490.0KiB client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945538: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 5, Chunks in use: 4. 5.04MiB allocated for chunks. 4.03MiB in use in bin. 4.03MiB client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945541: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945543: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945546: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945549: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945551: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945554: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945562: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945566: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 2, Chunks in use: 1. 881.57MiB allocated for chunks. 561.43MiB in use in bin. 560.30MiB client-requested in use in bin.\n",
      "2024-02-20 17:48:42.945569: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 560.30MiB was 256.00MiB, Chunk State: \n",
      "2024-02-20 17:48:42.945576: I external/local_tsl/tsl/framework/bfc_allocator.cc:1068]   Size: 320.14MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 1.01MiB | Requested Size: 1.01MiB | in_use: 1 | bin_num: -1\n",
      "2024-02-20 17:48:42.945579: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 930742272\n",
      "2024-02-20 17:48:42.945583: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521b0000000 of size 995328 next 1\n",
      "2024-02-20 17:48:42.945585: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521b00f3000 of size 1280 next 2\n",
      "2024-02-20 17:48:42.945588: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521b00f3500 of size 588701952 next 4\n",
      "2024-02-20 17:48:42.945590: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3261600 of size 1057536 next 6\n",
      "2024-02-20 17:48:42.945593: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3363900 of size 1057536 next 3\n",
      "2024-02-20 17:48:42.945595: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3465c00 of size 4096 next 8\n",
      "2024-02-20 17:48:42.945598: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3466c00 of size 4096 next 9\n",
      "2024-02-20 17:48:42.945600: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3467c00 of size 256 next 10\n",
      "2024-02-20 17:48:42.945603: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3467d00 of size 256 next 11\n",
      "2024-02-20 17:48:42.945606: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 1521d3467e00 of size 256 next 12\n",
      "2024-02-20 17:48:42.945608: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3467f00 of size 256 next 13\n",
      "2024-02-20 17:48:42.945611: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 1521d3468000 of size 256 next 14\n",
      "2024-02-20 17:48:42.945613: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3468100 of size 256 next 15\n",
      "2024-02-20 17:48:42.945616: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 1521d3468200 of size 52480 next 7\n",
      "2024-02-20 17:48:42.945618: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3474f00 of size 1057536 next 5\n",
      "2024-02-20 17:48:42.945621: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 1521d3577200 of size 1057536 next 17\n",
      "2024-02-20 17:48:42.945623: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 1521d3679500 of size 1057536 next 18\n",
      "2024-02-20 17:48:42.945626: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 1521d377b800 of size 335693824 next 18446744073709551615\n",
      "2024-02-20 17:48:42.945628: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-02-20 17:48:42.945633: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 256 totalling 1.0KiB\n",
      "2024-02-20 17:48:42.945636: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2024-02-20 17:48:42.945638: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 4096 totalling 8.0KiB\n",
      "2024-02-20 17:48:42.945641: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 995328 totalling 972.0KiB\n",
      "2024-02-20 17:48:42.945644: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 1057536 totalling 4.03MiB\n",
      "2024-02-20 17:48:42.945648: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 588701952 totalling 561.43MiB\n",
      "2024-02-20 17:48:42.945650: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 566.42MiB\n",
      "2024-02-20 17:48:42.945653: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 930742272 memory_limit_: 930742272 available bytes: 0 curr_region_allocation_bytes_: 1861484544\n",
      "2024-02-20 17:48:42.945660: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                       930742272\n",
      "InUse:                       593937920\n",
      "MaxInUse:                    594995456\n",
      "NumAllocs:                          38\n",
      "MaxAllocSize:                588701952\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-02-20 17:48:42.945664: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] ****************************************************************____________________________________\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m preprop\u001b[38;5;241m.\u001b[39mcompute_grid2mesh_features(grid_node_features)\n\u001b[1;32m     13\u001b[0m data \u001b[38;5;241m=\u001b[39m preprop\u001b[38;5;241m.\u001b[39mgrid2mesh_features\n\u001b[0;32m---> 15\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mto_graph_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrid2mesh_edges\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 21\u001b[0m, in \u001b[0;36mto_graph_tensor\u001b[0;34m(data, edge_set_name)\u001b[0m\n\u001b[1;32m     19\u001b[0m size \u001b[38;5;241m=\u001b[39m (data[node_set_name][subkey])\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# (n_nodes, batch_size, n_channels)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_set_name\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubkey\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[node_set_name][subkey]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m node_sets[node_set_name] \u001b[38;5;241m=\u001b[39m \u001b[43mtfgnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNodeSet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_fields\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mtfgnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHIDDEN_STATE\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_set_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msubkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43msizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subkey\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msenders\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     29\u001b[0m     source \u001b[38;5;241m=\u001b[39m (node_set_name, data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msenders\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n",
      "File \u001b[0;32m/work/mflora/miniconda3/envs/wofs-cast/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/work/mflora/miniconda3/envs/wofs-cast/lib/python3.10/site-packages/tensorflow_gnn/graph/graph_tensor.py:637\u001b[0m, in \u001b[0;36mNodeSet.from_fields\u001b[0;34m(cls, features, sizes, validate, *_)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    635\u001b[0m   validate \u001b[38;5;241m=\u001b[39m const\u001b[38;5;241m.\u001b[39mvalidate_graph_tensor_at_runtime\n\u001b[0;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_features_and_sizes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/work/mflora/miniconda3/envs/wofs-cast/lib/python3.10/site-packages/tensorflow_gnn/graph/graph_tensor.py:149\u001b[0m, in \u001b[0;36m_GraphPieceWithFeatures._from_features_and_sizes\u001b[0;34m(cls, features, sizes, validate, **extra_data)\u001b[0m\n\u001b[1;32m    146\u001b[0m sizes \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mconvert_to_tensor_or_ragged(sizes)\n\u001b[1;32m    147\u001b[0m gp\u001b[38;5;241m.\u001b[39mcheck_indices_dtype(sizes\u001b[38;5;241m.\u001b[39mdtype, what\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`sizes`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 149\u001b[0m prepared_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    150\u001b[0m     key: gp\u001b[38;5;241m.\u001b[39mconvert_to_tensor_or_ragged(value)\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    152\u001b[0m }\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    154\u001b[0m     _GraphPieceWithFeatures\u001b[38;5;241m.\u001b[39m_DATAKEY_FEATURES: prepared_features,\n\u001b[1;32m    155\u001b[0m     _GraphPieceWithFeatures\u001b[38;5;241m.\u001b[39m_DATAKEY_SIZES: sizes\n\u001b[1;32m    156\u001b[0m }\n\u001b[1;32m    157\u001b[0m data\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    158\u001b[0m     key: gp\u001b[38;5;241m.\u001b[39mconvert_to_tensor_or_ragged(value)\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m extra_data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    160\u001b[0m })\n",
      "File \u001b[0;32m/work/mflora/miniconda3/envs/wofs-cast/lib/python3.10/site-packages/tensorflow_gnn/graph/graph_tensor.py:150\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    146\u001b[0m sizes \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mconvert_to_tensor_or_ragged(sizes)\n\u001b[1;32m    147\u001b[0m gp\u001b[38;5;241m.\u001b[39mcheck_indices_dtype(sizes\u001b[38;5;241m.\u001b[39mdtype, what\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`sizes`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    149\u001b[0m prepared_features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 150\u001b[0m     key: \u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor_or_ragged\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    152\u001b[0m }\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    154\u001b[0m     _GraphPieceWithFeatures\u001b[38;5;241m.\u001b[39m_DATAKEY_FEATURES: prepared_features,\n\u001b[1;32m    155\u001b[0m     _GraphPieceWithFeatures\u001b[38;5;241m.\u001b[39m_DATAKEY_SIZES: sizes\n\u001b[1;32m    156\u001b[0m }\n\u001b[1;32m    157\u001b[0m data\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m    158\u001b[0m     key: gp\u001b[38;5;241m.\u001b[39mconvert_to_tensor_or_ragged(value)\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m extra_data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    160\u001b[0m })\n",
      "File \u001b[0;32m/work/mflora/miniconda3/envs/wofs-cast/lib/python3.10/site-packages/tensorflow_gnn/graph/graph_piece.py:47\u001b[0m, in \u001b[0;36mconvert_to_tensor_or_ragged\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_or_ragged\u001b[39m(value):\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Coerce objects other than ragged tensors to tensors.\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (value\n\u001b[1;32m     46\u001b[0m           \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (tf\u001b[38;5;241m.\u001b[39mRaggedTensor, GraphPieceBase))\n\u001b[0;32m---> 47\u001b[0m           \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Create the graph inputs. \n",
    "preprop = GNNDataPreprocessor(train_inputs, \n",
    "                 n_levels=len(pressure_levels), \n",
    "                 n_vars_3D=n_vars_3D, \n",
    "                 n_vars_2D=n_vars_2D,\n",
    "                 n_meshes=2, \n",
    "                 grid2mesh_radius=0.1, \n",
    "                 mesh2grid_edge_normalization_factor=None)\n",
    "\n",
    "grid_node_features = stack_dataset(train_inputs)\n",
    "\n",
    "preprop.compute_grid2mesh_features(grid_node_features)\n",
    "data = preprop.grid2mesh_features\n",
    "\n",
    "graph = to_graph_tensor(data, 'grid2mesh_edges')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b30cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f91d223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid_nodes': {'senders_node_features': array([[[ 3.2143555e+00,  4.0122070e+00,  5.9156418e-03, ...,\n",
       "            5.1528192e-01, -7.5325884e-02,  9.9715894e-01],\n",
       "          [ 3.2143555e+00,  4.0122070e+00,  5.9156418e-03, ...,\n",
       "            5.1528192e-01, -7.5325884e-02,  9.9715894e-01],\n",
       "          [ 3.2143555e+00,  4.0122070e+00,  5.9156418e-03, ...,\n",
       "            5.1528192e-01, -7.5325884e-02,  9.9715894e-01],\n",
       "          ...,\n",
       "          [ 3.2143555e+00,  4.0122070e+00,  5.9156418e-03, ...,\n",
       "            5.1528192e-01, -7.5325884e-02,  9.9715894e-01],\n",
       "          [ 3.2143555e+00,  4.0122070e+00,  5.9156418e-03, ...,\n",
       "            5.1528192e-01, -7.5325884e-02,  9.9715894e-01],\n",
       "          [ 3.2143555e+00,  4.0122070e+00,  5.9156418e-03, ...,\n",
       "            5.1528192e-01, -7.5325884e-02,  9.9715894e-01]],\n",
       "  \n",
       "         [[ 3.2749023e+00,  3.8867185e+00,  2.9263494e-03, ...,\n",
       "            5.1528192e-01, -7.5875051e-02,  9.9711734e-01],\n",
       "          [ 3.2749023e+00,  3.8867185e+00,  2.9263494e-03, ...,\n",
       "            5.1528192e-01, -7.5875051e-02,  9.9711734e-01],\n",
       "          [ 3.2749023e+00,  3.8867185e+00,  2.9263494e-03, ...,\n",
       "            5.1528192e-01, -7.5875051e-02,  9.9711734e-01],\n",
       "          ...,\n",
       "          [ 3.2749023e+00,  3.8867185e+00,  2.9263494e-03, ...,\n",
       "            5.1528192e-01, -7.5875051e-02,  9.9711734e-01],\n",
       "          [ 3.2749023e+00,  3.8867185e+00,  2.9263494e-03, ...,\n",
       "            5.1528192e-01, -7.5875051e-02,  9.9711734e-01],\n",
       "          [ 3.2749023e+00,  3.8867185e+00,  2.9263494e-03, ...,\n",
       "            5.1528192e-01, -7.5875051e-02,  9.9711734e-01]],\n",
       "  \n",
       "         [[ 3.3139648e+00,  3.7465820e+00,  2.1611452e-03, ...,\n",
       "            5.1528192e-01, -7.6424673e-02,  9.9707538e-01],\n",
       "          [ 3.3139648e+00,  3.7465820e+00,  2.1611452e-03, ...,\n",
       "            5.1528192e-01, -7.6424673e-02,  9.9707538e-01],\n",
       "          [ 3.3139648e+00,  3.7465820e+00,  2.1611452e-03, ...,\n",
       "            5.1528192e-01, -7.6424673e-02,  9.9707538e-01],\n",
       "          ...,\n",
       "          [ 3.3139648e+00,  3.7465820e+00,  2.1611452e-03, ...,\n",
       "            5.1528192e-01, -7.6424673e-02,  9.9707538e-01],\n",
       "          [ 3.3139648e+00,  3.7465820e+00,  2.1611452e-03, ...,\n",
       "            5.1528192e-01, -7.6424673e-02,  9.9707538e-01],\n",
       "          [ 3.3139648e+00,  3.7465820e+00,  2.1611452e-03, ...,\n",
       "            5.1528192e-01, -7.6424673e-02,  9.9707538e-01]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[-1.8928223e+00, -2.1411130e+00,  1.0375975e-03, ...,\n",
       "            6.3223028e-01, -2.3712507e-01,  9.7147912e-01],\n",
       "          [-1.8928223e+00, -2.1411130e+00,  1.0375975e-03, ...,\n",
       "            6.3223028e-01, -2.3712507e-01,  9.7147912e-01],\n",
       "          [-1.8928223e+00, -2.1411130e+00,  1.0375975e-03, ...,\n",
       "            6.3223028e-01, -2.3712507e-01,  9.7147912e-01],\n",
       "          ...,\n",
       "          [-1.8928223e+00, -2.1411130e+00,  1.0375975e-03, ...,\n",
       "            6.3223028e-01, -2.3712507e-01,  9.7147912e-01],\n",
       "          [-1.8928223e+00, -2.1411130e+00,  1.0375975e-03, ...,\n",
       "            6.3223028e-01, -2.3712507e-01,  9.7147912e-01],\n",
       "          [-1.8928223e+00, -2.1411130e+00,  1.0375975e-03, ...,\n",
       "            6.3223028e-01, -2.3712507e-01,  9.7147912e-01]],\n",
       "  \n",
       "         [[-1.7446289e+00, -2.1425781e+00,  2.4018288e-03, ...,\n",
       "            6.3223028e-01, -2.3766007e-01,  9.7134840e-01],\n",
       "          [-1.7446289e+00, -2.1425781e+00,  2.4018288e-03, ...,\n",
       "            6.3223028e-01, -2.3766007e-01,  9.7134840e-01],\n",
       "          [-1.7446289e+00, -2.1425781e+00,  2.4018288e-03, ...,\n",
       "            6.3223028e-01, -2.3766007e-01,  9.7134840e-01],\n",
       "          ...,\n",
       "          [-1.7446289e+00, -2.1425781e+00,  2.4018288e-03, ...,\n",
       "            6.3223028e-01, -2.3766007e-01,  9.7134840e-01],\n",
       "          [-1.7446289e+00, -2.1425781e+00,  2.4018288e-03, ...,\n",
       "            6.3223028e-01, -2.3766007e-01,  9.7134840e-01],\n",
       "          [-1.7446289e+00, -2.1425781e+00,  2.4018288e-03, ...,\n",
       "            6.3223028e-01, -2.3766007e-01,  9.7134840e-01]],\n",
       "  \n",
       "         [[-1.6496582e+00, -2.1757810e+00,  2.6252267e-03, ...,\n",
       "            6.3223028e-01, -2.3819546e-01,  9.7121722e-01],\n",
       "          [-1.6496582e+00, -2.1757810e+00,  2.6252267e-03, ...,\n",
       "            6.3223028e-01, -2.3819546e-01,  9.7121722e-01],\n",
       "          [-1.6496582e+00, -2.1757810e+00,  2.6252267e-03, ...,\n",
       "            6.3223028e-01, -2.3819546e-01,  9.7121722e-01],\n",
       "          ...,\n",
       "          [-1.6496582e+00, -2.1757810e+00,  2.6252267e-03, ...,\n",
       "            6.3223028e-01, -2.3819546e-01,  9.7121722e-01],\n",
       "          [-1.6496582e+00, -2.1757810e+00,  2.6252267e-03, ...,\n",
       "            6.3223028e-01, -2.3819546e-01,  9.7121722e-01],\n",
       "          [-1.6496582e+00, -2.1757810e+00,  2.6252267e-03, ...,\n",
       "            6.3223028e-01, -2.3819546e-01,  9.7121722e-01]]], dtype=float32)},\n",
       " 'mesh_nodes': {'receivers_node_features': <tf.Tensor: shape=(162, 32, 51), dtype=float32, numpy=\n",
       "  array([[[ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "            0.49999997,  0.86602545],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "            0.49999997,  0.86602545],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "            0.49999997,  0.86602545],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "            0.49999997,  0.86602545],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "            0.49999997,  0.86602545],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "            0.49999997,  0.86602545]],\n",
       "  \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "           -0.50000006,  0.8660254 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "           -0.50000006,  0.8660254 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "           -0.50000006,  0.8660254 ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "           -0.50000006,  0.8660254 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "           -0.50000006,  0.8660254 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "           -0.50000006,  0.8660254 ]],\n",
       "  \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "            1.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "            1.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "            1.        ,  0.        ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "            1.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "            1.        ,  0.        ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.7946544 ,\n",
       "            1.        ,  0.        ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.49112338,\n",
       "           -0.7380283 ,  0.6747698 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.49112338,\n",
       "           -0.7380283 ,  0.6747698 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.49112338,\n",
       "           -0.7380283 ,  0.6747698 ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.49112338,\n",
       "           -0.7380283 ,  0.6747698 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.49112338,\n",
       "           -0.7380283 ,  0.6747698 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.49112338,\n",
       "           -0.7380283 ,  0.6747698 ]],\n",
       "  \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "           -0.7135256 ,  0.7006292 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "           -0.7135256 ,  0.7006292 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "           -0.7135256 ,  0.7006292 ],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "           -0.7135256 ,  0.7006292 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "           -0.7135256 ,  0.7006292 ],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.18759258,\n",
       "           -0.7135256 ,  0.7006292 ]],\n",
       "  \n",
       "         [[ 0.        ,  0.        ,  0.        , ...,  0.303531  ,\n",
       "           -0.89484096,  0.44638506],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.303531  ,\n",
       "           -0.89484096,  0.44638506],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.303531  ,\n",
       "           -0.89484096,  0.44638506],\n",
       "          ...,\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.303531  ,\n",
       "           -0.89484096,  0.44638506],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.303531  ,\n",
       "           -0.89484096,  0.44638506],\n",
       "          [ 0.        ,  0.        ,  0.        , ...,  0.303531  ,\n",
       "           -0.89484096,  0.44638506]]], dtype=float32)>},\n",
       " 'edge_features': array([[[ 0.99822582, -0.01618737, -0.50194753,  0.86269428],\n",
       "         [ 0.99822582, -0.01618737, -0.50194753,  0.86269428],\n",
       "         [ 0.99822582, -0.01618737, -0.50194753,  0.86269428],\n",
       "         ...,\n",
       "         [ 0.99822582, -0.01618737, -0.50194753,  0.86269428],\n",
       "         [ 0.99822582, -0.01618737, -0.50194753,  0.86269428],\n",
       "         [ 0.99822582, -0.01618737, -0.50194753,  0.86269428]],\n",
       " \n",
       "        [[ 0.99085994, -0.01594978, -0.48737943,  0.86256033],\n",
       "         [ 0.99085994, -0.01594978, -0.48737943,  0.86256033],\n",
       "         [ 0.99085994, -0.01594978, -0.48737943,  0.86256033],\n",
       "         ...,\n",
       "         [ 0.99085994, -0.01594978, -0.48737943,  0.86256033],\n",
       "         [ 0.99085994, -0.01594978, -0.48737943,  0.86256033],\n",
       "         [ 0.99085994, -0.01594978, -0.48737943,  0.86256033]],\n",
       " \n",
       "        [[ 0.98365951, -0.01571921, -0.47281378,  0.86243033],\n",
       "         [ 0.98365951, -0.01571921, -0.47281378,  0.86243033],\n",
       "         [ 0.98365951, -0.01571921, -0.47281378,  0.86243033],\n",
       "         ...,\n",
       "         [ 0.98365951, -0.01571921, -0.47281378,  0.86243033],\n",
       "         [ 0.98365951, -0.01571921, -0.47281378,  0.86243033],\n",
       "         [ 0.98365951, -0.01571921, -0.47281378,  0.86243033]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.99588008, -0.01611042,  0.09483771,  0.99122319],\n",
       "         [ 0.99588008, -0.01611042,  0.09483771,  0.99122319],\n",
       "         [ 0.99588008, -0.01611042,  0.09483771,  0.99122319],\n",
       "         ...,\n",
       "         [ 0.99588008, -0.01611042,  0.09483771,  0.99122319],\n",
       "         [ 0.99588008, -0.01611042,  0.09483771,  0.99122319],\n",
       "         [ 0.99588008, -0.01611042,  0.09483771,  0.99122319]],\n",
       " \n",
       "        [[ 0.9973963 , -0.01616057,  0.10935608,  0.99125146],\n",
       "         [ 0.9973963 , -0.01616057,  0.10935608,  0.99125146],\n",
       "         [ 0.9973963 , -0.01616057,  0.10935608,  0.99125146],\n",
       "         ...,\n",
       "         [ 0.9973963 , -0.01616057,  0.10935608,  0.99125146],\n",
       "         [ 0.9973963 , -0.01616057,  0.10935608,  0.99125146],\n",
       "         [ 0.9973963 , -0.01616057,  0.10935608,  0.99125146]],\n",
       " \n",
       "        [[ 0.99912401, -0.01621583,  0.12387339,  0.99128262],\n",
       "         [ 0.99912401, -0.01621583,  0.12387339,  0.99128262],\n",
       "         [ 0.99912401, -0.01621583,  0.12387339,  0.99128262],\n",
       "         ...,\n",
       "         [ 0.99912401, -0.01621583,  0.12387339,  0.99128262],\n",
       "         [ 0.99912401, -0.01621583,  0.12387339,  0.99128262],\n",
       "         [ 0.99912401, -0.01621583,  0.12387339,  0.99128262]]]),\n",
       " 'senders': array([ 222,  223,  224,  225,  226,  227,  228,  229,  230,  231,  232,\n",
       "         233,  234,  235,  236,  237,  238,  239,  240,  241,  242,  243,\n",
       "         244,  245,  246,  247,  248,  249,  250,  251,  252,  253,  254,\n",
       "         255,  256,  257,  258,  259,  260,  261,  262,  263,  264,  265,\n",
       "         266,  267,  268,  269,  270,  271,  272,  273,  274,  275,  276,\n",
       "         277,  278,  279,  280,  281,  282,  283,  284,  285,  286,  287,\n",
       "         288,  289,  290,  291,  524,  525,  526,  527,  528,  529,  530,\n",
       "         531,  532,  533,  534,  535,  536,  537,  538,  539,  540,  541,\n",
       "         542,  543,  544,  545,  546,  547,  548,  549,  550,  551,  552,\n",
       "         553,  554,  555,  556,  557,  558,  559,  560,  561,  562,  563,\n",
       "         564,  565,  566,  567,  568,  569,  570,  571,  572,  573,  574,\n",
       "         575,  576,  577,  578,  579,  580,  581,  582,  583,  584,  585,\n",
       "         586,  587,  588,  589,  826,  827,  828,  829,  830,  831,  832,\n",
       "         833,  834,  835,  836,  837,  838,  839,  840,  841,  842,  843,\n",
       "         844,  845,  846,  847,  848,  849,  850,  851,  852,  853,  854,\n",
       "         855,  856,  857,  858,  859,  860,  861,  862,  863,  864,  865,\n",
       "         866,  867,  868,  869,  870,  871,  872,  873,  874,  875,  876,\n",
       "         877,  878,  879,  880,  881,  882,  883,  884,  885,  886,  887,\n",
       "        1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138,\n",
       "        1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149,\n",
       "        1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160,\n",
       "        1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171,\n",
       "        1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182,\n",
       "        1183, 1184, 1185, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437,\n",
       "        1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448,\n",
       "        1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459,\n",
       "        1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470,\n",
       "        1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481,\n",
       "        1482, 1483, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740,\n",
       "        1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751,\n",
       "        1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762,\n",
       "        1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773,\n",
       "        1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 2035, 2036, 2037,\n",
       "        2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048,\n",
       "        2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059,\n",
       "        2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070,\n",
       "        2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2338, 2339, 2340,\n",
       "        2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351,\n",
       "        2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362,\n",
       "        2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373,\n",
       "        2374, 2375, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650,\n",
       "        2651, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661,\n",
       "        2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2948,\n",
       "        2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959,\n",
       "        2960, 2961, 2962, 2963, 2964, 2965]),\n",
       " 'receivers': array([56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56,\n",
       "        56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprop.grid2mesh_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprop.grid2mesh_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb6a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class ToMeshGraphTensor(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "    def call(self, inputs):\n",
    "        return inputs \n",
    "    \n",
    "class ToMesh2GridGraphTensor(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "    def call(self, inputs):\n",
    "        return inputs \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafffa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = self.preprocessor._init_grid2mesh_tensor(inputs)\n",
    "\n",
    "\n",
    "def model_fn(gtspec: tfgnn.GraphTensorSpec): \n",
    "    graph = inputs = tf.keras.layers.Input(type_spec=gtspec)\n",
    "\n",
    "    # GRID2MESH ---------------------------------------------\n",
    "    #input_tensor = self.preprocessor._init_grid2mesh_tensor(inputs)\n",
    "    graph = self.grid2mesh_gnn(gtspec)\n",
    "\n",
    "    latent_mesh_nodes = graph.node_sets['mesh_nodes'][tfgnn.HIDDEN_STATE]\n",
    "    latent_grid_nodes = graph.node_sets['grid_nodes'][tfgnn.HIDDEN_STATE]\n",
    "\n",
    "    # MESH ---------------------------------------------\n",
    "    graph = self.preprocessor._init_mesh_tensor(latent_mesh_nodes)\n",
    "    graph = self.mesh_gnn(graph)\n",
    "    updated_latent_mesh_nodes = graph.node_sets['mesh_nodes'][tfgnn.HIDDEN_STATE]\n",
    "\n",
    "    # MESH2GRID ---------------------------------------------\n",
    "    graph = self.preprocessor._init_mesh2grid_tensor(updated_latent_mesh_nodes, \n",
    "                                                                latent_grid_nodes)\n",
    "    graph = self.mesh2grid_gnn(graph)\n",
    "    \n",
    "    return tf.keras.Model(inputs, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprop = GNNDataPreprocessor(train_inputs, \n",
    "                 n_levels=len(pressure_levels), \n",
    "                 n_vars_3D=n_vars_3D, \n",
    "                 n_vars_2D=n_vars_2D,\n",
    "                 n_meshes=2, \n",
    "                 grid2mesh_radius=0.1, \n",
    "                 mesh2grid_edge_normalization_factor=None)\n",
    "\n",
    "\n",
    "grid_node_features = stack_dataset(train_inputs)\n",
    "target_node_features = stack_dataset(train_targets)\n",
    "\n",
    "# Re-order so batch size is first \n",
    "grid_node_features_reshaped = tf.transpose(grid_node_features, perm=[1,0,2])\n",
    "target_node_features_reshaped = tf.transpose(target_node_features, perm=[1,0,2])\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((grid_node_features_reshaped, target_node_features_reshaped))\n",
    "train_ds = train_ds.shuffle(\n",
    "            buffer_size=2).batch(2).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b03adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphCast(preprop)\n",
    "\n",
    "#inputs = tf.keras.layers.Input(shape=(None, 90000, 48), name='my_input')\n",
    "#model.build((None, 90000, 48))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss = 'mse',\n",
    "             )\n",
    "#print(model.summary())\n",
    "model.fit(train_ds, shuffle=False, epochs=5)#, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70ea41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56f833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
